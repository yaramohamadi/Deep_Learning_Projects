{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADL_HW2_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vxBLk-xPX7Ko",
        "TaViV-Wcxwh6",
        "D2xIFKiCYq0f",
        "jNG25ryxaMEb",
        "WAg4gERQZ9yc",
        "AiSou_NIbiHn",
        "v7QFPFw9cIlR",
        "_jFlGgguFinZ",
        "o6fGbLKZdlXb",
        "bnW-Jp5kd_1L",
        "LWUhuvydeIR3",
        "p7DJRDdJeLP5",
        "06RtAxyue3Q6",
        "m0s_vd5Be8zZ",
        "MS21A1ckfAM4",
        "_2s8BGcHfIRC",
        "ifORDCdAjdxY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxBLk-xPX7Ko"
      },
      "source": [
        "# Getting stuff ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs6CWT_aKRhF",
        "outputId": "a0a2c8d9-b320-4777-90c1-fd9437c6f13f"
      },
      "source": [
        "gh repo clone ruizheliUOA/TWR-VAE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BigBiGAN-PyTorch'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 57 (delta 18), reused 51 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3gi1SO0b-h_",
        "outputId": "d27db9e4-67ee-409f-e13e-588ed072b5bf"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IXZI2LxFy_J",
        "outputId": "a9ae1b7e-b16d-42c7-b800-2fe69b40e9bc"
      },
      "source": [
        "pip install pytorch-fid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading https://files.pythonhosted.org/packages/93/54/49dc21a5ee774af0390813c3cf66af57af0a31ab22ba0c2ac02cdddeb755/pytorch-fid-0.2.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->pytorch-fid) (3.7.4.3)\n",
            "Building wheels for collected packages: pytorch-fid\n",
            "  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.0-cp37-none-any.whl size=10547 sha256=c2825fcd1973db8cb30dc5ea576a27283cfb74bb023e5f02b2b7589e12854eb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/36/3c/4f3fb256f62d24bef52636f66f21667bc21caa637ce92f0e53\n",
            "Successfully built pytorch-fid\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaViV-Wcxwh6"
      },
      "source": [
        "# Changing loss modes: \n",
        "\n",
        "in the following codes, different loss modes are used for model training:\n",
        "\n",
        "major changes in the code are in train_gan.py, pipeline.py and model/losses.py. Whereever there is a change there is a comment section like this: \n",
        "\n",
        "\\# Loss modes: description of change ###################\n",
        "\n",
        "my updated code\n",
        "\n",
        "\\##############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2xIFKiCYq0f"
      },
      "source": [
        "## Using all loss parts:\n",
        "\n",
        "some arguments are added to train_gan.py as follows: \n",
        "\n",
        "--loss_mode -> choices: (\"all\", \"no_sx\", \"no_sz\", \"no_sxz\", \"no_sx_sz\", \"info_gan\")\n",
        "\n",
        "-- train -> choices: (0, 1) indicates whether we are training or testing\n",
        "\n",
        "-- resume -> when in training mode we can load from checkpoint and specify which epoch to resume training from"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNG25ryxaMEb"
      },
      "source": [
        "#### Train\n",
        "\n",
        "as we see model is trained for 31 epochs and the last acheived loss is this:\n",
        "\n",
        "epoch 31, disc_loss 1.330464482307434, gen_enc_loss 1.0490446090698242"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp_u2VH5xv1c",
        "outputId": "3b1e0bf2-3392-4c82-9d62-17bf3ee3d4c8"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 1 --loss_mode \"all\" --resume 22"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from checkpoint, resuming from epoch: 22\n",
            "creating model from checkpoint\n",
            "2021-05-18 17:00:15.789994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]epoch 22, disc_loss 2.100839614868164, gen_enc_loss 0.8357255458831787\n",
            "50it [01:02,  1.23s/it]epoch 22, disc_loss 1.4718999862670898, gen_enc_loss 0.8557757139205933\n",
            "100it [02:04,  1.24s/it]epoch 22, disc_loss 1.5015583038330078, gen_enc_loss 0.9620881080627441\n",
            "150it [03:08,  1.27s/it]epoch 22, disc_loss 1.444177508354187, gen_enc_loss 0.9139944314956665\n",
            "200it [04:10,  1.25s/it]epoch 22, disc_loss 1.5130914449691772, gen_enc_loss 0.9368475675582886\n",
            "234it [04:53,  1.26s/it]\n",
            "0it [00:00, ?it/s]epoch 23, disc_loss 1.4531590938568115, gen_enc_loss 0.882318913936615\n",
            "50it [01:04,  1.27s/it]epoch 23, disc_loss 1.4208626747131348, gen_enc_loss 0.9608749151229858\n",
            "100it [02:07,  1.27s/it]epoch 23, disc_loss 1.5061206817626953, gen_enc_loss 0.940211296081543\n",
            "150it [03:11,  1.28s/it]epoch 23, disc_loss 1.756555438041687, gen_enc_loss 0.9730002284049988\n",
            "200it [04:15,  1.27s/it]epoch 23, disc_loss 1.5612739324569702, gen_enc_loss 0.917308509349823\n",
            "234it [04:59,  1.28s/it]\n",
            "0it [00:00, ?it/s]epoch 24, disc_loss 1.4016475677490234, gen_enc_loss 0.927091121673584\n",
            "50it [01:04,  1.27s/it]epoch 24, disc_loss 1.4446637630462646, gen_enc_loss 1.0351641178131104\n",
            "100it [02:08,  1.29s/it]epoch 24, disc_loss 1.363215684890747, gen_enc_loss 1.0767327547073364\n",
            "150it [03:12,  1.28s/it]epoch 24, disc_loss 1.3629951477050781, gen_enc_loss 1.0175015926361084\n",
            "200it [04:17,  1.34s/it]epoch 24, disc_loss 1.6350759267807007, gen_enc_loss 0.9357746839523315\n",
            "234it [05:00,  1.29s/it]\n",
            "0it [00:00, ?it/s]epoch 25, disc_loss 1.4768130779266357, gen_enc_loss 1.0202378034591675\n",
            "50it [01:04,  1.28s/it]epoch 25, disc_loss 1.5699453353881836, gen_enc_loss 1.0182921886444092\n",
            "100it [02:08,  1.28s/it]epoch 25, disc_loss 1.5413084030151367, gen_enc_loss 0.9582921862602234\n",
            "150it [03:12,  1.27s/it]epoch 25, disc_loss 1.493680715560913, gen_enc_loss 0.9165199995040894\n",
            "200it [04:15,  1.27s/it]epoch 25, disc_loss 1.394236445426941, gen_enc_loss 0.9647123217582703\n",
            "234it [04:59,  1.28s/it]\n",
            "0it [00:00, ?it/s]epoch 26, disc_loss 1.5194675922393799, gen_enc_loss 0.8101773262023926\n",
            "50it [01:04,  1.29s/it]epoch 26, disc_loss 1.6538381576538086, gen_enc_loss 0.876027524471283\n",
            "100it [02:09,  1.28s/it]epoch 26, disc_loss 1.574084997177124, gen_enc_loss 0.912225604057312\n",
            "150it [03:13,  1.28s/it]epoch 26, disc_loss 1.390567660331726, gen_enc_loss 1.0279451608657837\n",
            "200it [04:17,  1.28s/it]epoch 26, disc_loss 1.4642887115478516, gen_enc_loss 0.9692729711532593\n",
            "234it [05:01,  1.29s/it]\n",
            "0it [00:00, ?it/s]epoch 27, disc_loss 1.6013033390045166, gen_enc_loss 0.88249272108078\n",
            "50it [01:05,  1.34s/it]epoch 27, disc_loss 1.4103988409042358, gen_enc_loss 0.9620388746261597\n",
            "100it [02:09,  1.29s/it]epoch 27, disc_loss 1.4979045391082764, gen_enc_loss 0.84552401304245\n",
            "150it [03:13,  1.30s/it]epoch 27, disc_loss 1.5994653701782227, gen_enc_loss 0.8272775411605835\n",
            "200it [04:17,  1.29s/it]epoch 27, disc_loss 1.532802939414978, gen_enc_loss 0.8337687253952026\n",
            "234it [05:01,  1.29s/it]\n",
            "0it [00:00, ?it/s]epoch 28, disc_loss 1.4435491561889648, gen_enc_loss 0.7775825262069702\n",
            "50it [01:04,  1.28s/it]epoch 28, disc_loss 1.3825407028198242, gen_enc_loss 1.0137367248535156\n",
            "100it [02:09,  1.31s/it]epoch 28, disc_loss 1.4015765190124512, gen_enc_loss 0.9677488803863525\n",
            "150it [03:13,  1.28s/it]epoch 28, disc_loss 1.481583595275879, gen_enc_loss 0.7973756194114685\n",
            "200it [04:18,  1.32s/it]epoch 28, disc_loss 1.3490428924560547, gen_enc_loss 1.0052485466003418\n",
            "234it [05:01,  1.29s/it]\n",
            "0it [00:00, ?it/s]epoch 29, disc_loss 1.455771803855896, gen_enc_loss 0.847046971321106\n",
            "50it [01:04,  1.28s/it]epoch 29, disc_loss 1.6822433471679688, gen_enc_loss 0.9510407447814941\n",
            "100it [02:08,  1.28s/it]epoch 29, disc_loss 1.3434398174285889, gen_enc_loss 1.050729751586914\n",
            "150it [03:12,  1.27s/it]epoch 29, disc_loss 1.3630237579345703, gen_enc_loss 0.9652401208877563\n",
            "200it [04:16,  1.28s/it]epoch 29, disc_loss 1.4132665395736694, gen_enc_loss 1.0706217288970947\n",
            "234it [05:00,  1.28s/it]\n",
            "0it [00:00, ?it/s]epoch 30, disc_loss 1.4532102346420288, gen_enc_loss 1.0300214290618896\n",
            "50it [01:04,  1.29s/it]epoch 30, disc_loss 1.5818694829940796, gen_enc_loss 0.958768367767334\n",
            "100it [02:08,  1.28s/it]epoch 30, disc_loss 1.544294834136963, gen_enc_loss 0.8175781965255737\n",
            "150it [03:12,  1.27s/it]epoch 30, disc_loss 1.3350980281829834, gen_enc_loss 1.142624020576477\n",
            "200it [04:16,  1.28s/it]epoch 30, disc_loss 1.3817414045333862, gen_enc_loss 0.8499019145965576\n",
            "234it [05:00,  1.28s/it]\n",
            "0it [00:00, ?it/s]epoch 31, disc_loss 1.330464482307434, gen_enc_loss 1.0490446090698242\n",
            "8it [00:10,  1.34s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAg4gERQZ9yc"
      },
      "source": [
        "### Test\n",
        "\n",
        "in this mode a batch of original images are saved in \"data/org/\" directory and a batch of generated images are saved in \"data/MNIST/{loss_mode}/gen/\"  for later FID calculation and InceptionScore is calculated in the process. Furthermore encoded train and test codes (encoded images) with their labels are saved as CSV in \"data/MNIST/{loss_mode}/encoded/\"\n",
        "\n",
        "as we see InceptionScore in this mode is  1.1652391"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9h9vaHNJ54R",
        "outputId": "4fd637d2-87de-44ac-fabc-abb265cb9410"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"all\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original images saved\n",
            "creating generated image directory (save one batch\n",
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/drive/MyDrive/BigBiGAN-PyTorch-main/src/pipeline/pipeline.py:235: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n",
            "___________________________________\n",
            "Inception Score is ::::::  1.1652391\n",
            "___________________________________\n",
            "done\n",
            "0it [00:04, ?it/s]\n",
            "generated images saved\n",
            "encoded test csv saved\n",
            "encoded train csv saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiSou_NIbiHn"
      },
      "source": [
        "### FID\n",
        "\n",
        "pytorch FID library is used. because our images are very small compared to original input images af InceptionNet, --dims is chosen as 192 which implies using a shallower CNN structure\n",
        "\n",
        "FID in this mode is 0.3373776426348982"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywZZhaf2TR3P",
        "outputId": "e8ef5799-00c2-4200-8cd5-49cf69d8c8d2"
      },
      "source": [
        "!python -m pytorch_fid \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/org/\" \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/all/gen/\" --dims 192 --device \"cuda\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:01<00:00, 56.0MB/s]\n",
            "100% 6/6 [01:08<00:00, 11.41s/it]\n",
            "100% 6/6 [00:02<00:00,  2.97it/s]\n",
            "FID:  0.3373776426348982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QFPFw9cIlR"
      },
      "source": [
        "### Linear Accuracy\n",
        "\n",
        "KNN (n = 3) classifier is used and accuracy on test is 0.15775240384615385 when trained for 30 epochs. When I trained on only 10 epochs, it would only yield 10% accuracy. I believe more accuracy can be acheived with more training as the decoder learns to succesfully decode and generate images. Furthermore in VAE because the encoder tries to learn a latent with little to no covvariance among it's dimensions, it is plausible to have low linear accuracy\n",
        "\n",
        "linear accuracy is 0.15775240384615385"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLOeyZoxT3N0",
        "outputId": "c9e7651d-0640-43d9-fd7a-087971fbd8d3"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/all/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/all/encoded/test.csv\")\n",
        "\n",
        "train_y, train_X = train_df.loc[:, \"0\"], train_df.loc[:, \"1\":\"100\"]\n",
        "test_y, test_X = test_df.loc[:, \"0\"], test_df.loc[:, \"1\":\"100\"]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(train_X, train_y)\n",
        "neigh.score(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15775240384615385"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jFlGgguFinZ"
      },
      "source": [
        "## No SZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6fGbLKZdlXb"
      },
      "source": [
        "### Training\n",
        "\n",
        "--loss_mode: \"no_sz\"\n",
        "\n",
        "training is done for 9 epochs and loss is as follows:\n",
        "\n",
        "epoch 9, disc_loss 1.576092004776001, gen_enc_loss 1.3424787521362305"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hph_0-SSGcPa",
        "outputId": "6207fe76-3dab-4bc3-f9d3-a0dbff09ca6a"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 1 --loss_mode \"no_sz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no_sz\n",
            "2021-05-13 08:15:59.441843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]epoch 0, disc_loss 3.277395248413086, gen_enc_loss 1.4751172065734863\n",
            "50it [00:47,  1.05it/s]epoch 0, disc_loss 0.038688644766807556, gen_enc_loss 5.039902687072754\n",
            "100it [01:35,  1.04it/s]epoch 0, disc_loss 0.08507563173770905, gen_enc_loss 4.818063735961914\n",
            "150it [02:24,  1.03it/s]epoch 0, disc_loss 0.07505977153778076, gen_enc_loss 4.643559455871582\n",
            "200it [03:12,  1.02it/s]epoch 0, disc_loss 0.24523942172527313, gen_enc_loss 4.300935745239258\n",
            "234it [03:46,  1.03it/s]\n",
            "0it [00:00, ?it/s]epoch 1, disc_loss 0.21476471424102783, gen_enc_loss 3.9550118446350098\n",
            "50it [00:55,  1.10s/it]epoch 1, disc_loss 0.14024361968040466, gen_enc_loss 3.992415428161621\n",
            "100it [01:50,  1.09s/it]epoch 1, disc_loss 0.4261084198951721, gen_enc_loss 3.3422980308532715\n",
            "150it [02:45,  1.10s/it]epoch 1, disc_loss 0.3949705958366394, gen_enc_loss 3.0097944736480713\n",
            "200it [03:40,  1.10s/it]epoch 1, disc_loss 0.6017751693725586, gen_enc_loss 3.0236740112304688\n",
            "234it [04:18,  1.10s/it]\n",
            "0it [00:00, ?it/s]epoch 2, disc_loss 0.7065201997756958, gen_enc_loss 2.5524253845214844\n",
            "50it [00:55,  1.12s/it]epoch 2, disc_loss 0.8430721163749695, gen_enc_loss 2.2954964637756348\n",
            "100it [01:51,  1.13s/it]epoch 2, disc_loss 0.5917046666145325, gen_enc_loss 2.7231931686401367\n",
            "150it [02:46,  1.09s/it]epoch 2, disc_loss 0.8408117890357971, gen_enc_loss 2.2615344524383545\n",
            "200it [03:41,  1.12s/it]epoch 2, disc_loss 0.7725324630737305, gen_enc_loss 2.3695602416992188\n",
            "234it [04:19,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 3, disc_loss 0.8396285772323608, gen_enc_loss 2.4640941619873047\n",
            "50it [00:55,  1.11s/it]epoch 3, disc_loss 0.7799234986305237, gen_enc_loss 2.5901105403900146\n",
            "100it [01:51,  1.11s/it]epoch 3, disc_loss 0.9121881127357483, gen_enc_loss 2.0518691539764404\n",
            "150it [02:46,  1.10s/it]epoch 3, disc_loss 0.8532918691635132, gen_enc_loss 2.156954765319824\n",
            "200it [03:42,  1.10s/it]epoch 3, disc_loss 0.6927876472473145, gen_enc_loss 2.6721248626708984\n",
            "234it [04:19,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 4, disc_loss 1.033169150352478, gen_enc_loss 2.0969886779785156\n",
            "50it [00:55,  1.10s/it]epoch 4, disc_loss 0.9250196218490601, gen_enc_loss 2.2802484035491943\n",
            "100it [01:50,  1.10s/it]epoch 4, disc_loss 1.0070114135742188, gen_enc_loss 2.009706497192383\n",
            "150it [02:46,  1.11s/it]epoch 4, disc_loss 1.2554688453674316, gen_enc_loss 2.2726259231567383\n",
            "200it [03:41,  1.11s/it]epoch 4, disc_loss 1.3196572065353394, gen_enc_loss 2.0244946479797363\n",
            "234it [04:19,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 5, disc_loss 1.093125820159912, gen_enc_loss 1.644437551498413\n",
            "50it [00:55,  1.11s/it]epoch 5, disc_loss 1.082734227180481, gen_enc_loss 1.5280760526657104\n",
            "100it [01:51,  1.10s/it]epoch 5, disc_loss 1.0440342426300049, gen_enc_loss 1.6544578075408936\n",
            "150it [02:47,  1.10s/it]epoch 5, disc_loss 1.082324504852295, gen_enc_loss 1.7464255094528198\n",
            "200it [03:42,  1.11s/it]epoch 5, disc_loss 1.1878337860107422, gen_enc_loss 1.5568859577178955\n",
            "234it [04:20,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 6, disc_loss 1.002155065536499, gen_enc_loss 1.8086885213851929\n",
            "50it [00:55,  1.12s/it]epoch 6, disc_loss 1.0987460613250732, gen_enc_loss 1.8580904006958008\n",
            "100it [01:51,  1.12s/it]epoch 6, disc_loss 1.251122236251831, gen_enc_loss 1.601858139038086\n",
            "150it [02:47,  1.11s/it]epoch 6, disc_loss 1.2046177387237549, gen_enc_loss 1.519005298614502\n",
            "200it [03:42,  1.12s/it]epoch 6, disc_loss 1.2575976848602295, gen_enc_loss 1.5635687112808228\n",
            "234it [04:20,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 7, disc_loss 1.1704819202423096, gen_enc_loss 1.4390839338302612\n",
            "50it [00:55,  1.11s/it]epoch 7, disc_loss 1.1705708503723145, gen_enc_loss 1.5851999521255493\n",
            "100it [01:51,  1.10s/it]epoch 7, disc_loss 1.3247990608215332, gen_enc_loss 1.2098575830459595\n",
            "150it [02:46,  1.11s/it]epoch 7, disc_loss 1.3504395484924316, gen_enc_loss 1.3773328065872192\n",
            "200it [03:42,  1.10s/it]epoch 7, disc_loss 1.18984854221344, gen_enc_loss 1.4273130893707275\n",
            "234it [04:20,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 8, disc_loss 1.1303019523620605, gen_enc_loss 1.6435455083847046\n",
            "50it [00:56,  1.11s/it]epoch 8, disc_loss 1.3764172792434692, gen_enc_loss 1.5072656869888306\n",
            "100it [01:51,  1.10s/it]epoch 8, disc_loss 1.251509428024292, gen_enc_loss 1.2336121797561646\n",
            "150it [02:47,  1.11s/it]epoch 8, disc_loss 1.4414992332458496, gen_enc_loss 1.0518982410430908\n",
            "200it [03:42,  1.13s/it]epoch 8, disc_loss 1.1091156005859375, gen_enc_loss 1.552067756652832\n",
            "234it [04:20,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 9, disc_loss 1.576092004776001, gen_enc_loss 1.3424787521362305\n",
            "50it [00:55,  1.10s/it]epoch 9, disc_loss 1.2548041343688965, gen_enc_loss 1.085956335067749\n",
            "100it [01:51,  1.10s/it]epoch 9, disc_loss 1.1703318357467651, gen_enc_loss 1.2819284200668335\n",
            "150it [02:47,  1.12s/it]epoch 9, disc_loss 1.1535700559616089, gen_enc_loss 1.5674183368682861\n",
            "200it [03:42,  1.11s/it]epoch 9, disc_loss 1.2230628728866577, gen_enc_loss 1.3518338203430176\n",
            "234it [04:20,  1.11s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnW-Jp5kd_1L"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMLxRz954lRM",
        "outputId": "ae8dded0-89a3-4e09-9ed1-63683f40c55a"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"no_sz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original images saved\n",
            "generated images saved\n",
            "creating encoded test csv file\n",
            "39it [00:02, 15.14it/s]\n",
            "saved encoded\n",
            "encoded test csv saved\n",
            "creating encoded train csv file\n",
            "234it [00:16, 14.00it/s]\n",
            "saved encoded\n",
            "encoded train csv saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWUhuvydeIR3"
      },
      "source": [
        "### FID\n",
        "\n",
        "FID:  0.7777843195290473"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j5KzgNgEFeH",
        "outputId": "17886232-7595-4dba-9416-0ef083076cab"
      },
      "source": [
        "!python -m pytorch_fid \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/org/\" \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sz/gen/\" --dims 192 --device \"cuda\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:01<00:00, 58.6MB/s]\n",
            "100% 6/6 [01:07<00:00, 11.23s/it]\n",
            "100% 6/6 [00:50<00:00,  8.43s/it]\n",
            "FID:  0.7777843195290473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7DJRDdJeLP5"
      },
      "source": [
        "### Linear Accuracy\n",
        "\n",
        "linear accuracy 0.12419871794871795"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz_js0SMEGF1",
        "outputId": "011b11f3-7bd8-42fd-a8b8-0db93d278f57"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sz/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sz/encoded/test.csv\")\n",
        "\n",
        "train_y, train_X = train_df.loc[:, \"0\"], train_df.loc[:, \"1\":\"100\"]\n",
        "test_y, test_X = test_df.loc[:, \"0\"], test_df.loc[:, \"1\":\"100\"]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(train_X, train_y)\n",
        "neigh.score(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12419871794871795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQS1LpS8HKXw"
      },
      "source": [
        "## No S_XZ\n",
        "\n",
        "This mode is extra and the question does not ask to calculate statistics for this mode. in this mode the combination of Sx and Sz are occluded but Sx and Sz alone are present in calculation of loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06RtAxyue3Q6"
      },
      "source": [
        "### Training\n",
        "\n",
        "--loss_mode: \"no_sxz\"\n",
        "\n",
        "epoch 9, disc_loss 1.0040082931518555, gen_enc_loss 0.7531461715698242"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a8LbSj5HMVj",
        "outputId": "3f730d48-e5e2-437c-cdac-b39adbd08da6"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 1 --loss_mode \"no_sxz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no_sxz\n",
            "2021-05-14 09:07:20.028347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]epoch 0, disc_loss 2.1846747398376465, gen_enc_loss 1.4773368835449219\n",
            "50it [00:46,  1.09it/s]epoch 0, disc_loss 0.820879340171814, gen_enc_loss 2.2447586059570312\n",
            "100it [01:32,  1.07it/s]epoch 0, disc_loss 0.6836590766906738, gen_enc_loss 2.638072967529297\n",
            "150it [02:19,  1.07it/s]epoch 0, disc_loss 0.7129312753677368, gen_enc_loss 2.3289573192596436\n",
            "200it [03:06,  1.05it/s]epoch 0, disc_loss 0.7315065264701843, gen_enc_loss 2.9692811965942383\n",
            "234it [03:38,  1.07it/s]\n",
            "0it [00:00, ?it/s]epoch 1, disc_loss 0.6966474056243896, gen_enc_loss 2.1858129501342773\n",
            "50it [00:53,  1.07s/it]epoch 1, disc_loss 0.712207019329071, gen_enc_loss 2.0193371772766113\n",
            "100it [01:47,  1.09s/it]epoch 1, disc_loss 0.7861006259918213, gen_enc_loss 1.4559266567230225\n",
            "150it [02:42,  1.10s/it]epoch 1, disc_loss 0.8251285552978516, gen_enc_loss 1.4546031951904297\n",
            "200it [03:37,  1.10s/it]epoch 1, disc_loss 0.8397979736328125, gen_enc_loss 1.5272891521453857\n",
            "234it [04:14,  1.09s/it]\n",
            "0it [00:00, ?it/s]epoch 2, disc_loss 0.8665785789489746, gen_enc_loss 1.4156861305236816\n",
            "50it [00:55,  1.09s/it]epoch 2, disc_loss 0.8681804537773132, gen_enc_loss 1.1875711679458618\n",
            "100it [01:49,  1.09s/it]epoch 2, disc_loss 0.8392426371574402, gen_enc_loss 1.7539116144180298\n",
            "150it [02:45,  1.11s/it]epoch 2, disc_loss 0.912375807762146, gen_enc_loss 1.6457395553588867\n",
            "200it [03:40,  1.12s/it]epoch 2, disc_loss 0.8725106120109558, gen_enc_loss 1.556583285331726\n",
            "234it [04:18,  1.10s/it]\n",
            "0it [00:00, ?it/s]epoch 3, disc_loss 0.8530694842338562, gen_enc_loss 1.5669467449188232\n",
            "50it [00:55,  1.09s/it]epoch 3, disc_loss 0.8963939547538757, gen_enc_loss 1.4690834283828735\n",
            "100it [01:50,  1.16s/it]epoch 3, disc_loss 0.9321691393852234, gen_enc_loss 1.180504322052002\n",
            "150it [02:45,  1.10s/it]epoch 3, disc_loss 0.9508757591247559, gen_enc_loss 1.2969108819961548\n",
            "200it [03:40,  1.10s/it]epoch 3, disc_loss 0.9052524566650391, gen_enc_loss 1.4866149425506592\n",
            "234it [04:18,  1.10s/it]\n",
            "0it [00:00, ?it/s]epoch 4, disc_loss 0.8951563835144043, gen_enc_loss 1.3573570251464844\n",
            "50it [00:55,  1.10s/it]epoch 4, disc_loss 0.9536194205284119, gen_enc_loss 1.071530818939209\n",
            "100it [01:50,  1.09s/it]epoch 4, disc_loss 0.9420409202575684, gen_enc_loss 1.2772003412246704\n",
            "150it [02:45,  1.10s/it]epoch 4, disc_loss 1.039120078086853, gen_enc_loss 0.7244982719421387\n",
            "200it [03:40,  1.11s/it]epoch 4, disc_loss 0.9621509313583374, gen_enc_loss 1.0610604286193848\n",
            "234it [04:18,  1.10s/it]\n",
            "0it [00:00, ?it/s]epoch 5, disc_loss 1.0038821697235107, gen_enc_loss 1.0885064601898193\n",
            "50it [00:55,  1.09s/it]epoch 5, disc_loss 1.049166202545166, gen_enc_loss 0.7628003358840942\n",
            "100it [01:50,  1.10s/it]epoch 5, disc_loss 1.1058580875396729, gen_enc_loss 0.693629264831543\n",
            "150it [02:46,  1.10s/it]epoch 5, disc_loss 1.021730899810791, gen_enc_loss 1.0025725364685059\n",
            "200it [03:41,  1.10s/it]epoch 5, disc_loss 1.0004658699035645, gen_enc_loss 1.0804767608642578\n",
            "234it [04:19,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 6, disc_loss 1.0090491771697998, gen_enc_loss 1.2558157444000244\n",
            "50it [00:55,  1.12s/it]epoch 6, disc_loss 0.9970409274101257, gen_enc_loss 1.2700917720794678\n",
            "100it [01:52,  1.11s/it]epoch 6, disc_loss 1.0582560300827026, gen_enc_loss 0.951399564743042\n",
            "150it [02:47,  1.11s/it]epoch 6, disc_loss 1.2395342588424683, gen_enc_loss 0.44922924041748047\n",
            "200it [03:43,  1.11s/it]epoch 6, disc_loss 1.0455275774002075, gen_enc_loss 0.947721540927887\n",
            "234it [04:20,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 7, disc_loss 1.039954662322998, gen_enc_loss 0.9084963202476501\n",
            "50it [00:56,  1.12s/it]epoch 7, disc_loss 1.0001912117004395, gen_enc_loss 0.9788321256637573\n",
            "100it [01:51,  1.10s/it]epoch 7, disc_loss 1.0923972129821777, gen_enc_loss 0.7016806602478027\n",
            "150it [02:47,  1.10s/it]epoch 7, disc_loss 1.0498955249786377, gen_enc_loss 0.8334227800369263\n",
            "200it [03:42,  1.12s/it]epoch 7, disc_loss 1.0279061794281006, gen_enc_loss 0.9511312246322632\n",
            "234it [04:20,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 8, disc_loss 1.0727765560150146, gen_enc_loss 0.6896324157714844\n",
            "50it [00:56,  1.11s/it]epoch 8, disc_loss 1.0472460985183716, gen_enc_loss 1.034987211227417\n",
            "100it [01:51,  1.11s/it]epoch 8, disc_loss 1.0468813180923462, gen_enc_loss 0.8224791288375854\n",
            "150it [02:47,  1.11s/it]epoch 8, disc_loss 1.034454584121704, gen_enc_loss 0.8581071496009827\n",
            "200it [03:42,  1.11s/it]epoch 8, disc_loss 1.0760011672973633, gen_enc_loss 0.6599818468093872\n",
            "234it [04:20,  1.11s/it]\n",
            "0it [00:00, ?it/s]epoch 9, disc_loss 1.0040082931518555, gen_enc_loss 0.7531461715698242\n",
            "50it [00:55,  1.10s/it]epoch 9, disc_loss 1.0660443305969238, gen_enc_loss 0.8338319063186646\n",
            "100it [01:51,  1.11s/it]epoch 9, disc_loss 1.0393521785736084, gen_enc_loss 1.1445329189300537\n",
            "150it [02:47,  1.11s/it]epoch 9, disc_loss 1.0713849067687988, gen_enc_loss 0.6424457430839539\n",
            "200it [03:42,  1.10s/it]epoch 9, disc_loss 1.0197811126708984, gen_enc_loss 0.8124094009399414\n",
            "234it [04:20,  1.11s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0s_vd5Be8zZ"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYyZ3kkaJ4z4",
        "outputId": "1e58efdb-36c2-4ecb-aae8-8e809fec0336"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"no_sxz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original images saved\n",
            "creating generated image directory (save one batch\n",
            "0it [00:00, ?it/s]\n",
            "  0% 0/256 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/256 [00:00<00:16, 15.57it/s]\u001b[A\n",
            "  2% 4/256 [00:00<00:18, 13.85it/s]\u001b[A\n",
            "  2% 5/256 [00:00<00:21, 11.59it/s]\u001b[A\n",
            "  2% 6/256 [00:00<00:26,  9.58it/s]\u001b[A\n",
            "  3% 7/256 [00:00<00:29,  8.43it/s]\u001b[A\n",
            "  3% 8/256 [00:00<00:32,  7.59it/s]\u001b[A\n",
            "  4% 9/256 [00:01<00:36,  6.75it/s]\u001b[A\n",
            "  4% 10/256 [00:01<00:40,  6.08it/s]\u001b[A\n",
            "  4% 11/256 [00:01<00:44,  5.48it/s]\u001b[A\n",
            "  5% 12/256 [00:01<00:48,  4.99it/s]\u001b[A\n",
            "  5% 13/256 [00:01<00:52,  4.63it/s]\u001b[A\n",
            "  5% 14/256 [00:02<00:56,  4.25it/s]\u001b[A\n",
            "  6% 15/256 [00:02<01:00,  3.97it/s]\u001b[A\n",
            "  6% 16/256 [00:02<01:04,  3.71it/s]\u001b[A\n",
            "  7% 17/256 [00:03<01:08,  3.49it/s]\u001b[A\n",
            "  7% 18/256 [00:03<01:12,  3.30it/s]\u001b[A\n",
            "  7% 19/256 [00:03<01:16,  3.12it/s]\u001b[A\n",
            "  8% 20/256 [00:04<01:20,  2.94it/s]\u001b[A\n",
            "  8% 21/256 [00:04<01:23,  2.80it/s]\u001b[A\n",
            "  9% 22/256 [00:05<01:27,  2.66it/s]\u001b[A\n",
            "  9% 23/256 [00:05<01:31,  2.55it/s]\u001b[A\n",
            "  9% 24/256 [00:05<01:35,  2.44it/s]\u001b[A\n",
            " 10% 25/256 [00:06<01:39,  2.32it/s]\u001b[A\n",
            " 10% 26/256 [00:07<01:52,  2.04it/s]\u001b[A\n",
            " 11% 27/256 [00:07<01:52,  2.03it/s]\u001b[A\n",
            " 11% 28/256 [00:08<01:53,  2.00it/s]\u001b[A\n",
            " 11% 29/256 [00:08<01:55,  1.97it/s]\u001b[A\n",
            " 12% 30/256 [00:09<01:57,  1.93it/s]\u001b[A\n",
            " 12% 31/256 [00:09<02:00,  1.86it/s]\u001b[A\n",
            " 12% 32/256 [00:10<02:04,  1.80it/s]\u001b[A\n",
            " 13% 33/256 [00:10<02:06,  1.76it/s]\u001b[A\n",
            " 13% 34/256 [00:11<02:09,  1.71it/s]\u001b[A\n",
            " 14% 35/256 [00:12<02:13,  1.65it/s]\u001b[A\n",
            " 14% 36/256 [00:12<02:17,  1.60it/s]\u001b[A\n",
            " 14% 37/256 [00:13<02:20,  1.56it/s]\u001b[A\n",
            " 15% 38/256 [00:14<02:23,  1.52it/s]\u001b[A\n",
            " 15% 39/256 [00:14<02:25,  1.49it/s]\u001b[A\n",
            " 16% 40/256 [00:15<02:30,  1.44it/s]\u001b[A\n",
            " 16% 41/256 [00:16<02:33,  1.40it/s]\u001b[A\n",
            " 16% 42/256 [00:17<02:36,  1.37it/s]\u001b[A\n",
            " 17% 43/256 [00:18<02:38,  1.34it/s]\u001b[A\n",
            " 17% 44/256 [00:18<02:41,  1.31it/s]\u001b[A\n",
            " 18% 45/256 [00:19<02:44,  1.28it/s]\u001b[A\n",
            " 18% 46/256 [00:20<02:46,  1.26it/s]\u001b[A\n",
            " 18% 47/256 [00:21<02:48,  1.24it/s]\u001b[A\n",
            " 19% 48/256 [00:22<02:50,  1.22it/s]\u001b[A\n",
            " 19% 49/256 [00:23<02:54,  1.19it/s]\u001b[A\n",
            " 20% 50/256 [00:23<02:58,  1.16it/s]\u001b[A\n",
            " 20% 51/256 [00:24<02:58,  1.15it/s]\u001b[A\n",
            " 20% 52/256 [00:25<03:04,  1.10it/s]\u001b[A\n",
            " 21% 53/256 [00:26<03:06,  1.09it/s]\u001b[A\n",
            " 21% 54/256 [00:27<03:09,  1.07it/s]\u001b[A\n",
            " 21% 55/256 [00:28<03:12,  1.05it/s]\u001b[A\n",
            " 22% 56/256 [00:29<03:13,  1.03it/s]\u001b[A\n",
            " 22% 57/256 [00:30<03:15,  1.02it/s]\u001b[A\n",
            " 23% 58/256 [00:31<03:21,  1.02s/it]\u001b[A\n",
            " 23% 59/256 [00:32<03:24,  1.04s/it]\u001b[A\n",
            " 23% 60/256 [00:34<03:24,  1.04s/it]\u001b[A\n",
            " 24% 61/256 [00:35<03:24,  1.05s/it]\u001b[A\n",
            " 24% 62/256 [00:36<03:25,  1.06s/it]\u001b[A\n",
            " 25% 63/256 [00:37<03:29,  1.08s/it]\u001b[A\n",
            " 25% 64/256 [00:38<03:30,  1.10s/it]\u001b[A\n",
            " 25% 65/256 [00:39<03:30,  1.10s/it]\u001b[A\n",
            " 26% 66/256 [00:40<03:32,  1.12s/it]\u001b[A\n",
            " 26% 67/256 [00:41<03:35,  1.14s/it]\u001b[A\n",
            " 27% 68/256 [00:43<03:36,  1.15s/it]\u001b[A\n",
            " 27% 69/256 [00:44<03:41,  1.18s/it]\u001b[A\n",
            " 27% 70/256 [00:45<03:44,  1.21s/it]\u001b[A\n",
            " 28% 71/256 [00:46<03:46,  1.22s/it]\u001b[A\n",
            " 28% 72/256 [00:48<03:46,  1.23s/it]\u001b[A\n",
            " 29% 73/256 [00:49<03:53,  1.27s/it]\u001b[A\n",
            " 29% 74/256 [00:50<03:55,  1.30s/it]\u001b[A\n",
            " 29% 75/256 [00:52<03:59,  1.32s/it]\u001b[A\n",
            " 30% 76/256 [00:53<04:00,  1.34s/it]\u001b[A\n",
            " 30% 77/256 [00:55<04:04,  1.36s/it]\u001b[A\n",
            " 30% 78/256 [00:56<04:06,  1.38s/it]\u001b[A\n",
            " 31% 79/256 [00:57<04:09,  1.41s/it]\u001b[A\n",
            " 31% 80/256 [00:59<04:12,  1.43s/it]\u001b[A\n",
            " 32% 81/256 [01:00<04:13,  1.45s/it]\u001b[A\n",
            " 32% 82/256 [01:02<04:13,  1.46s/it]\u001b[A\n",
            " 32% 83/256 [01:03<04:14,  1.47s/it]\u001b[A\n",
            " 33% 84/256 [01:05<04:16,  1.49s/it]\u001b[A\n",
            " 33% 85/256 [01:06<04:15,  1.50s/it]\u001b[A\n",
            " 34% 86/256 [01:08<04:18,  1.52s/it]\u001b[A\n",
            " 34% 87/256 [01:10<04:21,  1.55s/it]\u001b[A\n",
            " 34% 88/256 [01:11<04:21,  1.56s/it]\u001b[A\n",
            " 35% 89/256 [01:13<04:24,  1.58s/it]\u001b[A\n",
            " 35% 90/256 [01:14<04:25,  1.60s/it]\u001b[A\n",
            " 36% 91/256 [01:16<04:25,  1.61s/it]\u001b[A\n",
            " 36% 92/256 [01:18<04:27,  1.63s/it]\u001b[A\n",
            " 36% 93/256 [01:19<04:27,  1.64s/it]\u001b[A\n",
            " 37% 94/256 [01:21<04:26,  1.65s/it]\u001b[A\n",
            " 37% 95/256 [01:23<04:27,  1.66s/it]\u001b[A\n",
            " 38% 96/256 [01:25<04:27,  1.67s/it]\u001b[A\n",
            " 38% 97/256 [01:26<04:30,  1.70s/it]\u001b[A\n",
            " 38% 98/256 [01:28<04:31,  1.72s/it]\u001b[A\n",
            " 39% 99/256 [01:30<04:37,  1.77s/it]\u001b[A\n",
            " 39% 100/256 [01:32<04:35,  1.77s/it]\u001b[A\n",
            " 39% 101/256 [01:33<04:34,  1.77s/it]\u001b[A\n",
            " 40% 102/256 [01:35<04:33,  1.77s/it]\u001b[A\n",
            " 40% 103/256 [01:37<04:34,  1.79s/it]\u001b[A\n",
            " 41% 104/256 [01:39<04:34,  1.80s/it]\u001b[A\n",
            " 41% 105/256 [01:41<04:34,  1.82s/it]\u001b[A\n",
            " 41% 106/256 [01:43<04:32,  1.82s/it]\u001b[A\n",
            " 42% 107/256 [01:44<04:33,  1.84s/it]\u001b[A\n",
            " 42% 108/256 [01:46<04:33,  1.85s/it]\u001b[A\n",
            " 43% 109/256 [01:48<04:32,  1.86s/it]\u001b[A\n",
            " 43% 110/256 [01:50<04:33,  1.87s/it]\u001b[A\n",
            " 43% 111/256 [01:52<04:36,  1.90s/it]\u001b[A\n",
            " 44% 112/256 [01:54<04:37,  1.93s/it]\u001b[A\n",
            " 44% 113/256 [01:56<04:37,  1.94s/it]\u001b[A\n",
            " 45% 114/256 [01:58<04:37,  1.96s/it]\u001b[A\n",
            " 45% 115/256 [02:00<04:37,  1.97s/it]\u001b[A\n",
            " 45% 116/256 [02:02<04:37,  1.98s/it]\u001b[A\n",
            " 46% 117/256 [02:04<04:38,  2.00s/it]\u001b[A\n",
            " 46% 118/256 [02:06<04:38,  2.02s/it]\u001b[A\n",
            " 46% 119/256 [02:08<04:39,  2.04s/it]\u001b[A\n",
            " 47% 120/256 [02:10<04:40,  2.06s/it]\u001b[A\n",
            " 47% 121/256 [02:12<04:39,  2.07s/it]\u001b[A\n",
            " 48% 122/256 [02:15<04:43,  2.11s/it]\u001b[A\n",
            " 48% 123/256 [02:17<04:45,  2.15s/it]\u001b[A\n",
            " 48% 124/256 [02:19<04:46,  2.17s/it]\u001b[A\n",
            " 49% 125/256 [02:21<04:48,  2.20s/it]\u001b[A\n",
            " 49% 126/256 [02:24<04:51,  2.24s/it]\u001b[A\n",
            " 50% 127/256 [02:26<04:50,  2.25s/it]\u001b[A\n",
            " 50% 128/256 [02:28<04:48,  2.25s/it]\u001b[A\n",
            " 50% 129/256 [02:31<04:47,  2.26s/it]\u001b[A\n",
            " 51% 130/256 [02:33<04:46,  2.27s/it]\u001b[A\n",
            " 51% 131/256 [02:35<04:48,  2.31s/it]\u001b[A\n",
            " 52% 132/256 [02:38<04:47,  2.32s/it]\u001b[A\n",
            " 52% 133/256 [02:40<04:47,  2.34s/it]\u001b[A\n",
            " 52% 134/256 [02:42<04:45,  2.34s/it]\u001b[A\n",
            " 53% 135/256 [02:45<04:44,  2.35s/it]\u001b[A\n",
            " 53% 136/256 [02:47<04:42,  2.35s/it]\u001b[A\n",
            " 54% 137/256 [02:49<04:41,  2.37s/it]\u001b[A\n",
            " 54% 138/256 [02:52<04:41,  2.39s/it]\u001b[A\n",
            " 54% 139/256 [02:54<04:41,  2.41s/it]\u001b[A\n",
            " 55% 140/256 [02:57<04:40,  2.42s/it]\u001b[A\n",
            " 55% 141/256 [02:59<04:39,  2.43s/it]\u001b[A\n",
            " 55% 142/256 [03:02<04:38,  2.44s/it]\u001b[A\n",
            " 56% 143/256 [03:04<04:37,  2.46s/it]\u001b[A\n",
            " 56% 144/256 [03:07<04:36,  2.47s/it]\u001b[A\n",
            " 57% 145/256 [03:09<04:35,  2.48s/it]\u001b[A\n",
            " 57% 146/256 [03:12<04:33,  2.49s/it]\u001b[A\n",
            " 57% 147/256 [03:14<04:33,  2.51s/it]\u001b[A\n",
            " 58% 148/256 [03:17<04:32,  2.53s/it]\u001b[A\n",
            " 58% 149/256 [03:19<04:31,  2.54s/it]\u001b[A\n",
            " 59% 150/256 [03:22<04:30,  2.55s/it]\u001b[A\n",
            " 59% 151/256 [03:25<04:30,  2.58s/it]\u001b[A\n",
            " 59% 152/256 [03:27<04:29,  2.59s/it]\u001b[A\n",
            " 60% 153/256 [03:30<04:28,  2.61s/it]\u001b[A\n",
            " 60% 154/256 [03:33<04:26,  2.61s/it]\u001b[A\n",
            " 61% 155/256 [03:35<04:25,  2.63s/it]\u001b[A\n",
            " 61% 156/256 [03:38<04:24,  2.65s/it]\u001b[A\n",
            " 61% 157/256 [03:41<04:23,  2.67s/it]\u001b[A\n",
            " 62% 158/256 [03:43<04:24,  2.70s/it]\u001b[A\n",
            " 62% 159/256 [03:46<04:23,  2.71s/it]\u001b[A\n",
            " 62% 160/256 [03:49<04:21,  2.73s/it]\u001b[A\n",
            " 63% 161/256 [03:52<04:19,  2.73s/it]\u001b[A\n",
            " 63% 162/256 [03:54<04:18,  2.75s/it]\u001b[A\n",
            " 64% 163/256 [03:57<04:17,  2.77s/it]\u001b[A\n",
            " 64% 164/256 [04:00<04:17,  2.79s/it]\u001b[A\n",
            " 64% 165/256 [04:03<04:16,  2.82s/it]\u001b[A\n",
            " 65% 166/256 [04:06<04:15,  2.83s/it]\u001b[A\n",
            " 65% 167/256 [04:09<04:13,  2.85s/it]\u001b[A\n",
            " 66% 168/256 [04:12<04:12,  2.87s/it]\u001b[A\n",
            " 66% 169/256 [04:15<04:12,  2.91s/it]\u001b[A\n",
            " 66% 170/256 [04:18<04:11,  2.93s/it]\u001b[A\n",
            " 67% 171/256 [04:21<04:09,  2.94s/it]\u001b[A\n",
            " 67% 172/256 [04:24<04:08,  2.96s/it]\u001b[A\n",
            " 68% 173/256 [04:27<04:06,  2.97s/it]\u001b[A\n",
            " 68% 174/256 [04:30<04:04,  2.98s/it]\u001b[A\n",
            " 68% 175/256 [04:33<04:02,  2.99s/it]\u001b[A\n",
            " 69% 176/256 [04:36<04:00,  3.00s/it]\u001b[A\n",
            " 69% 177/256 [04:39<03:58,  3.01s/it]\u001b[A\n",
            " 70% 178/256 [04:42<03:55,  3.03s/it]\u001b[A\n",
            " 70% 179/256 [04:45<03:54,  3.04s/it]\u001b[A\n",
            " 70% 180/256 [04:48<03:53,  3.07s/it]\u001b[A\n",
            " 71% 181/256 [04:51<03:51,  3.08s/it]\u001b[A\n",
            " 71% 182/256 [04:54<03:48,  3.09s/it]\u001b[A\n",
            " 71% 183/256 [04:57<03:46,  3.10s/it]\u001b[A\n",
            " 72% 184/256 [05:00<03:43,  3.11s/it]\u001b[A\n",
            " 72% 185/256 [05:04<03:41,  3.12s/it]\u001b[A\n",
            " 73% 186/256 [05:07<03:40,  3.14s/it]\u001b[A\n",
            " 73% 187/256 [05:10<03:37,  3.15s/it]\u001b[A\n",
            " 73% 188/256 [05:13<03:36,  3.19s/it]\u001b[A\n",
            " 74% 189/256 [05:16<03:34,  3.20s/it]\u001b[A\n",
            " 74% 190/256 [05:20<03:33,  3.23s/it]\u001b[A\n",
            " 75% 191/256 [05:23<03:32,  3.27s/it]\u001b[A\n",
            " 75% 192/256 [05:26<03:30,  3.29s/it]\u001b[A\n",
            " 75% 193/256 [05:30<03:28,  3.31s/it]\u001b[A\n",
            " 76% 194/256 [05:33<03:26,  3.33s/it]\u001b[A\n",
            " 76% 195/256 [05:37<03:23,  3.34s/it]\u001b[A\n",
            " 77% 196/256 [05:40<03:21,  3.36s/it]\u001b[A\n",
            " 77% 197/256 [05:43<03:18,  3.37s/it]\u001b[A\n",
            " 77% 198/256 [05:47<03:16,  3.39s/it]\u001b[A\n",
            " 78% 199/256 [05:50<03:13,  3.40s/it]\u001b[A\n",
            " 78% 200/256 [05:54<03:11,  3.43s/it]\u001b[A\n",
            " 79% 201/256 [05:57<03:09,  3.44s/it]\u001b[A\n",
            " 79% 202/256 [06:01<03:06,  3.45s/it]\u001b[A\n",
            " 79% 203/256 [06:04<03:03,  3.46s/it]\u001b[A\n",
            " 80% 204/256 [06:08<03:00,  3.48s/it]\u001b[A\n",
            " 80% 205/256 [06:11<02:58,  3.49s/it]\u001b[A\n",
            " 80% 206/256 [06:15<02:55,  3.51s/it]\u001b[A\n",
            " 81% 207/256 [06:18<02:52,  3.53s/it]\u001b[A\n",
            " 81% 208/256 [06:22<02:49,  3.54s/it]\u001b[A\n",
            " 82% 209/256 [06:25<02:47,  3.56s/it]\u001b[A\n",
            " 82% 210/256 [06:29<02:44,  3.57s/it]\u001b[A\n",
            " 82% 211/256 [06:33<02:41,  3.59s/it]\u001b[A\n",
            " 83% 212/256 [06:36<02:38,  3.61s/it]\u001b[A\n",
            " 83% 213/256 [06:40<02:36,  3.64s/it]\u001b[A\n",
            " 84% 214/256 [06:44<02:33,  3.67s/it]\u001b[A\n",
            " 84% 215/256 [06:47<02:31,  3.69s/it]\u001b[A\n",
            " 84% 216/256 [06:51<02:27,  3.69s/it]\u001b[A\n",
            " 85% 217/256 [06:55<02:25,  3.72s/it]\u001b[A\n",
            " 85% 218/256 [06:59<02:22,  3.74s/it]\u001b[A\n",
            " 86% 219/256 [07:03<02:19,  3.77s/it]\u001b[A\n",
            " 86% 220/256 [07:06<02:15,  3.77s/it]\u001b[A\n",
            " 86% 221/256 [07:10<02:12,  3.77s/it]\u001b[A\n",
            " 87% 222/256 [07:14<02:08,  3.78s/it]\u001b[A\n",
            " 87% 223/256 [07:18<02:05,  3.79s/it]\u001b[A\n",
            " 88% 224/256 [07:22<02:01,  3.80s/it]\u001b[A\n",
            " 88% 225/256 [07:25<01:58,  3.82s/it]\u001b[A\n",
            " 88% 226/256 [07:29<01:55,  3.83s/it]\u001b[A\n",
            " 89% 227/256 [07:33<01:51,  3.86s/it]\u001b[A\n",
            " 89% 228/256 [07:37<01:48,  3.87s/it]\u001b[A\n",
            " 89% 229/256 [07:41<01:45,  3.89s/it]\u001b[A\n",
            " 90% 230/256 [07:45<01:41,  3.91s/it]\u001b[A\n",
            " 90% 231/256 [07:49<01:37,  3.91s/it]\u001b[A\n",
            " 91% 232/256 [07:53<01:34,  3.94s/it]\u001b[A\n",
            " 91% 233/256 [07:57<01:30,  3.95s/it]\u001b[A\n",
            " 91% 234/256 [08:01<01:27,  3.96s/it]\u001b[A\n",
            " 92% 235/256 [08:05<01:23,  3.98s/it]\u001b[A\n",
            " 92% 236/256 [08:09<01:19,  4.00s/it]\u001b[A\n",
            " 93% 237/256 [08:13<01:16,  4.01s/it]\u001b[A\n",
            " 93% 238/256 [08:17<01:12,  4.05s/it]\u001b[A\n",
            " 93% 239/256 [08:21<01:09,  4.07s/it]\u001b[A\n",
            " 94% 240/256 [08:25<01:05,  4.08s/it]\u001b[A\n",
            " 94% 241/256 [08:29<01:01,  4.09s/it]\u001b[A\n",
            " 95% 242/256 [08:34<00:57,  4.11s/it]\u001b[A\n",
            " 95% 243/256 [08:38<00:53,  4.11s/it]\u001b[A\n",
            " 95% 244/256 [08:42<00:49,  4.12s/it]\u001b[A\n",
            " 96% 245/256 [08:46<00:45,  4.14s/it]\u001b[A\n",
            " 96% 246/256 [08:50<00:41,  4.15s/it]\u001b[A\n",
            " 96% 247/256 [08:54<00:37,  4.16s/it]\u001b[A\n",
            " 97% 248/256 [08:59<00:33,  4.18s/it]\u001b[A\n",
            " 97% 249/256 [09:03<00:29,  4.19s/it]\u001b[A\n",
            " 98% 250/256 [09:07<00:25,  4.22s/it]\u001b[A\n",
            " 98% 251/256 [09:12<00:21,  4.25s/it]\u001b[A\n",
            " 98% 252/256 [09:16<00:17,  4.29s/it]\u001b[A\n",
            " 99% 253/256 [09:20<00:12,  4.31s/it]\u001b[A\n",
            " 99% 254/256 [09:25<00:08,  4.34s/it]\u001b[A\n",
            "100% 255/256 [09:29<00:04,  4.35s/it]\u001b[A\n",
            "100% 256/256 [09:33<00:00,  2.24s/it]\n",
            "1it [09:34, 574.01s/it]done\n",
            "generated images saved\n",
            "creating encoded test csv file\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "3it [00:00, 26.58it/s]\u001b[A\n",
            "6it [00:00, 26.96it/s]\u001b[A\n",
            "9it [00:00, 27.03it/s]\u001b[A\n",
            "12it [00:00, 27.61it/s]\u001b[A\n",
            "15it [00:00, 27.56it/s]\u001b[A\n",
            "18it [00:00, 28.10it/s]\u001b[A\n",
            "21it [00:00, 28.14it/s]\u001b[A\n",
            "24it [00:00, 28.24it/s]\u001b[A\n",
            "27it [00:00, 27.74it/s]\u001b[A\n",
            "30it [00:01, 27.17it/s]\u001b[A\n",
            "33it [00:01, 27.36it/s]\u001b[A\n",
            "36it [00:01, 27.19it/s]\u001b[A\n",
            "39it [00:01, 27.51it/s]\n",
            "saved encoded\n",
            "encoded test csv saved\n",
            "creating encoded train csv file\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "3it [00:00, 27.02it/s]\u001b[A\n",
            "6it [00:00, 27.45it/s]\u001b[A\n",
            "9it [00:00, 27.52it/s]\u001b[A\n",
            "12it [00:00, 26.65it/s]\u001b[A\n",
            "15it [00:00, 26.81it/s]\u001b[A\n",
            "18it [00:00, 26.93it/s]\u001b[A\n",
            "21it [00:00, 27.28it/s]\u001b[A\n",
            "24it [00:00, 27.39it/s]\u001b[A\n",
            "27it [00:00, 27.75it/s]\u001b[A\n",
            "30it [00:01, 28.02it/s]\u001b[A\n",
            "33it [00:01, 27.92it/s]\u001b[A\n",
            "36it [00:01, 27.46it/s]\u001b[A\n",
            "39it [00:01, 27.33it/s]\u001b[A\n",
            "42it [00:01, 27.50it/s]\u001b[A\n",
            "45it [00:01, 26.74it/s]\u001b[A\n",
            "48it [00:01, 26.36it/s]\u001b[A\n",
            "51it [00:01, 26.52it/s]\u001b[A\n",
            "54it [00:01, 26.14it/s]\u001b[A\n",
            "57it [00:02, 26.35it/s]\u001b[A\n",
            "60it [00:02, 26.03it/s]\u001b[A\n",
            "63it [00:02, 25.77it/s]\u001b[A\n",
            "66it [00:02, 26.05it/s]\u001b[A\n",
            "69it [00:02, 25.76it/s]\u001b[A\n",
            "72it [00:02, 25.33it/s]\u001b[A\n",
            "75it [00:02, 25.55it/s]\u001b[A\n",
            "78it [00:02, 25.39it/s]\u001b[A\n",
            "81it [00:03, 25.65it/s]\u001b[A\n",
            "84it [00:03, 25.81it/s]\u001b[A\n",
            "87it [00:03, 25.79it/s]\u001b[A\n",
            "90it [00:03, 25.65it/s]\u001b[A\n",
            "93it [00:03, 25.17it/s]\u001b[A\n",
            "96it [00:03, 25.24it/s]\u001b[A\n",
            "99it [00:03, 24.94it/s]\u001b[A\n",
            "102it [00:03, 24.38it/s]\u001b[A\n",
            "105it [00:04, 24.30it/s]\u001b[A\n",
            "108it [00:04, 24.10it/s]\u001b[A\n",
            "111it [00:04, 23.57it/s]\u001b[A\n",
            "114it [00:04, 23.54it/s]\u001b[A\n",
            "117it [00:04, 23.79it/s]\u001b[A\n",
            "120it [00:04, 23.96it/s]\u001b[A\n",
            "123it [00:04, 23.60it/s]\u001b[A\n",
            "126it [00:04, 23.76it/s]\u001b[A\n",
            "129it [00:05, 23.69it/s]\u001b[A\n",
            "132it [00:05, 23.64it/s]\u001b[A\n",
            "135it [00:05, 20.31it/s]\u001b[A\n",
            "138it [00:05, 20.98it/s]\u001b[A\n",
            "141it [00:05, 21.32it/s]\u001b[A\n",
            "144it [00:05, 21.79it/s]\u001b[A\n",
            "147it [00:05, 22.01it/s]\u001b[A\n",
            "150it [00:06, 22.36it/s]\u001b[A\n",
            "153it [00:06, 22.39it/s]\u001b[A\n",
            "156it [00:06, 21.55it/s]\u001b[A\n",
            "159it [00:06, 21.71it/s]\u001b[A\n",
            "162it [00:06, 21.93it/s]\u001b[A\n",
            "165it [00:06, 22.07it/s]\u001b[A\n",
            "168it [00:06, 21.71it/s]\u001b[A\n",
            "171it [00:06, 21.79it/s]\u001b[A\n",
            "174it [00:07, 22.13it/s]\u001b[A\n",
            "177it [00:07, 22.26it/s]\u001b[A\n",
            "180it [00:07, 22.22it/s]\u001b[A\n",
            "183it [00:07, 22.22it/s]\u001b[A\n",
            "186it [00:07, 22.19it/s]\u001b[A\n",
            "189it [00:07, 21.29it/s]\u001b[A\n",
            "192it [00:07, 21.31it/s]\u001b[A\n",
            "195it [00:08, 20.89it/s]\u001b[A\n",
            "198it [00:08, 21.10it/s]\u001b[A\n",
            "201it [00:08, 21.15it/s]\u001b[A\n",
            "204it [00:08, 21.00it/s]\u001b[A\n",
            "207it [00:08, 21.21it/s]\u001b[A\n",
            "210it [00:08, 20.88it/s]\u001b[A\n",
            "213it [00:08, 20.96it/s]\u001b[A\n",
            "216it [00:09, 21.00it/s]\u001b[A\n",
            "219it [00:09, 20.79it/s]\u001b[A\n",
            "222it [00:09, 20.89it/s]\u001b[A\n",
            "225it [00:09, 20.60it/s]\u001b[A\n",
            "228it [00:09, 20.71it/s]\u001b[A\n",
            "231it [00:09, 20.38it/s]\u001b[A\n",
            "234it [00:09, 23.43it/s]\n",
            "saved encoded\n",
            "encoded train csv saved\n",
            "1it [09:56, 596.67s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS21A1ckfAM4"
      },
      "source": [
        "### FID\n",
        "\n",
        "FID:  5.818132081007027"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGL7AsoGJ5cP",
        "outputId": "d7aea88d-a398-4732-effb-307246af9bd5"
      },
      "source": [
        "!python -m pytorch_fid \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/org/\" \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sxz/gen/\" --dims 192 --device \"cuda\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:00<00:00, 113MB/s]\n",
            "100% 6/6 [00:28<00:00,  4.79s/it]\n",
            "100% 6/6 [00:01<00:00,  3.80it/s]\n",
            "FID:  5.818132081007027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2s8BGcHfIRC"
      },
      "source": [
        "### Linear Accuracy\n",
        "\n",
        "0.10717147435897435"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_euES_IqJ71v",
        "outputId": "3f65c1c7-ad6e-4b2a-9812-0dd2743dc413"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sxz/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sxz/encoded/test.csv\")\n",
        "\n",
        "train_y, train_X = train_df.loc[:, \"0\"], train_df.loc[:, \"1\":\"100\"]\n",
        "test_y, test_X = test_df.loc[:, \"0\"], test_df.loc[:, \"1\":\"100\"]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(train_X, train_y)\n",
        "neigh.score(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10717147435897435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H3i_O-WyDdw"
      },
      "source": [
        "# InfoGAN\n",
        "\n",
        "in the following codes, a new mode for model training is added: infogan\n",
        "\n",
        "major changes in the code are in train_gan.py, pipeline.py, architecture.py, model/generator.py, model/discriminator.py and model/losses.py. Whereever there is a change there is a comment section like this: \n",
        "\n",
        "\\# InfoGan: description of change ###################\n",
        "\n",
        "my updated code\n",
        "\n",
        "\\###########################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mo_1P2xU-n9"
      },
      "source": [
        "### Training \n",
        "\n",
        "--loss_mode: \"info_gan\"\n",
        "\n",
        "if we are in info_gan mode, in pipeline.py a new 10 class uniform random onehot vector is passed to the generator. \n",
        "\n",
        "the generator takes a Z vector with length of 100 and a onehot vector (C) with length of 10. It replaces the first 10 values of Z with C and training is done. This information flows through the encoder during training too and the encoder's first 10 values of its output try to reconstruct C.\n",
        "\n",
        "In the descriminator, a second output is created where it takes the representation of the one but last layer, adds a linear layer with non linear activations and a softmax with 10 variables as output. \n",
        "\n",
        "In the loss, if in info_gan mode, the reconstruction loss just like loss_mode: \"all\" is created and on top of that a new term is added to the loss of both generator and discriminator where both try to minimize it.\n",
        "\n",
        "this term is the cross entropy of actual C and predicted C in both real and generated images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVSGraCfcy4I",
        "outputId": "ec8c63d9-a67a-4475-e385-51b521be0a4e"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 1 --loss_mode \"info_gan\" --resume 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from checkpoint, resuming from epoch: 10\n",
            "creating model from checkpoint\n",
            "2021-05-20 11:30:51.752855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]epoch 10, disc_loss 12.954505920410156, gen_enc_loss 33.04377365112305\n",
            "50it [01:16,  1.51s/it]epoch 10, disc_loss 11.627837181091309, gen_enc_loss 9.11083984375\n",
            "100it [02:31,  1.52s/it]epoch 10, disc_loss 9.46716022491455, gen_enc_loss 9.098752975463867\n",
            "150it [03:47,  1.51s/it]epoch 10, disc_loss 9.720191955566406, gen_enc_loss 15.017335891723633\n",
            "200it [05:02,  1.51s/it]epoch 10, disc_loss 9.092279434204102, gen_enc_loss 12.242772102355957\n",
            "234it [05:54,  1.52s/it]\n",
            "0it [00:00, ?it/s]epoch 11, disc_loss 9.75343132019043, gen_enc_loss 10.209104537963867\n",
            "50it [01:16,  1.55s/it]epoch 11, disc_loss 10.225789070129395, gen_enc_loss 5.3207502365112305\n",
            "100it [02:33,  1.55s/it]epoch 11, disc_loss 10.878839492797852, gen_enc_loss 7.120940208435059\n",
            "150it [03:50,  1.53s/it]epoch 11, disc_loss 10.475685119628906, gen_enc_loss 7.330505847930908\n",
            "200it [05:06,  1.53s/it]epoch 11, disc_loss 11.004953384399414, gen_enc_loss 7.714789390563965\n",
            "234it [05:59,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 12, disc_loss 10.693214416503906, gen_enc_loss 7.953007698059082\n",
            "50it [01:16,  1.53s/it]epoch 12, disc_loss 11.562528610229492, gen_enc_loss 8.653081893920898\n",
            "100it [02:32,  1.52s/it]epoch 12, disc_loss 11.301363945007324, gen_enc_loss 9.490438461303711\n",
            "150it [03:49,  1.53s/it]epoch 12, disc_loss 11.736324310302734, gen_enc_loss 14.640954971313477\n",
            "200it [05:05,  1.51s/it]epoch 12, disc_loss 9.417642593383789, gen_enc_loss 12.70933723449707\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 13, disc_loss 11.600339889526367, gen_enc_loss 12.85548210144043\n",
            "50it [01:16,  1.53s/it]epoch 13, disc_loss 7.195465087890625, gen_enc_loss 11.320865631103516\n",
            "100it [02:32,  1.52s/it]epoch 13, disc_loss 7.636186599731445, gen_enc_loss 12.96647834777832\n",
            "150it [03:49,  1.52s/it]epoch 13, disc_loss 11.545812606811523, gen_enc_loss 9.22858715057373\n",
            "200it [05:05,  1.52s/it]epoch 13, disc_loss 12.092905044555664, gen_enc_loss 15.474390029907227\n",
            "234it [05:56,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 14, disc_loss 13.377361297607422, gen_enc_loss 16.107990264892578\n",
            "50it [01:16,  1.52s/it]epoch 14, disc_loss 9.83969497680664, gen_enc_loss 15.562835693359375\n",
            "100it [02:32,  1.52s/it]epoch 14, disc_loss 5.147591590881348, gen_enc_loss 6.618674278259277\n",
            "150it [03:49,  1.52s/it]epoch 14, disc_loss 9.959339141845703, gen_enc_loss 12.381114959716797\n",
            "200it [05:05,  1.53s/it]epoch 14, disc_loss 11.218664169311523, gen_enc_loss 13.91602897644043\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 15, disc_loss 8.749380111694336, gen_enc_loss 9.698766708374023\n",
            "50it [01:16,  1.52s/it]epoch 15, disc_loss 6.469553470611572, gen_enc_loss 9.06550407409668\n",
            "100it [02:33,  1.52s/it]epoch 15, disc_loss 8.754971504211426, gen_enc_loss 11.941683769226074\n",
            "150it [03:49,  1.51s/it]epoch 15, disc_loss 10.764759063720703, gen_enc_loss 11.193971633911133\n",
            "200it [05:05,  1.52s/it]epoch 15, disc_loss 9.821981430053711, gen_enc_loss 16.733654022216797\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 16, disc_loss 7.960901737213135, gen_enc_loss 15.838838577270508\n",
            "50it [01:16,  1.52s/it]epoch 16, disc_loss 10.982193946838379, gen_enc_loss 15.266032218933105\n",
            "100it [02:33,  1.53s/it]epoch 16, disc_loss 14.94106388092041, gen_enc_loss 18.16135025024414\n",
            "150it [03:49,  1.52s/it]epoch 16, disc_loss 14.69366455078125, gen_enc_loss 18.55591583251953\n",
            "200it [05:05,  1.52s/it]epoch 16, disc_loss 10.228034973144531, gen_enc_loss 8.971354484558105\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 17, disc_loss 11.113153457641602, gen_enc_loss 8.673554420471191\n",
            "50it [01:17,  1.52s/it]epoch 17, disc_loss 12.35869312286377, gen_enc_loss 16.954072952270508\n",
            "100it [02:33,  1.52s/it]epoch 17, disc_loss 11.954292297363281, gen_enc_loss 19.783754348754883\n",
            "150it [03:49,  1.53s/it]epoch 17, disc_loss 2.2963790893554688, gen_enc_loss 2.310596466064453\n",
            "200it [05:05,  1.53s/it]epoch 17, disc_loss 10.742632865905762, gen_enc_loss 8.43986701965332\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 18, disc_loss 10.489387512207031, gen_enc_loss 10.99605941772461\n",
            "50it [01:17,  1.52s/it]epoch 18, disc_loss 11.6727933883667, gen_enc_loss 17.940134048461914\n",
            "100it [02:33,  1.53s/it]epoch 18, disc_loss 12.408555030822754, gen_enc_loss 11.011709213256836\n",
            "150it [03:49,  1.54s/it]epoch 18, disc_loss 13.544855117797852, gen_enc_loss 20.732223510742188\n",
            "200it [05:06,  1.53s/it]epoch 18, disc_loss 14.15280818939209, gen_enc_loss 11.354490280151367\n",
            "234it [05:58,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 19, disc_loss 9.407309532165527, gen_enc_loss 12.268474578857422\n",
            "50it [01:17,  1.53s/it]epoch 19, disc_loss 9.466503143310547, gen_enc_loss 9.7189359664917\n",
            "100it [02:33,  1.52s/it]epoch 19, disc_loss 10.678592681884766, gen_enc_loss 12.019104957580566\n",
            "150it [03:49,  1.52s/it]epoch 19, disc_loss 9.911946296691895, gen_enc_loss 15.749814987182617\n",
            "200it [05:06,  1.53s/it]epoch 19, disc_loss 12.170490264892578, gen_enc_loss 17.55218505859375\n",
            "234it [05:58,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 20, disc_loss 9.819963455200195, gen_enc_loss 18.753782272338867\n",
            "50it [01:16,  1.53s/it]epoch 20, disc_loss 8.04430103302002, gen_enc_loss 7.160572528839111\n",
            "100it [02:32,  1.53s/it]epoch 20, disc_loss 10.700401306152344, gen_enc_loss 9.139871597290039\n",
            "150it [03:49,  1.58s/it]epoch 20, disc_loss 10.745071411132812, gen_enc_loss 10.860878944396973\n",
            "200it [05:05,  1.53s/it]epoch 20, disc_loss 9.658432006835938, gen_enc_loss 18.75579071044922\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 21, disc_loss 10.706934928894043, gen_enc_loss 16.754467010498047\n",
            "50it [01:17,  1.52s/it]epoch 21, disc_loss 11.72879695892334, gen_enc_loss 14.469219207763672\n",
            "100it [02:33,  1.54s/it]epoch 21, disc_loss 11.238397598266602, gen_enc_loss 16.646217346191406\n",
            "150it [03:50,  1.53s/it]epoch 21, disc_loss 13.671113014221191, gen_enc_loss 14.26192855834961\n",
            "200it [05:06,  1.51s/it]epoch 21, disc_loss 8.495869636535645, gen_enc_loss 11.284208297729492\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 22, disc_loss 7.168304920196533, gen_enc_loss 19.612934112548828\n",
            "50it [01:17,  1.52s/it]epoch 22, disc_loss 11.319459915161133, gen_enc_loss 14.61276626586914\n",
            "100it [02:33,  1.52s/it]epoch 22, disc_loss 8.523895263671875, gen_enc_loss 14.737648010253906\n",
            "150it [03:50,  1.53s/it]epoch 22, disc_loss 10.302927017211914, gen_enc_loss 18.455354690551758\n",
            "200it [05:06,  1.52s/it]epoch 22, disc_loss 12.336102485656738, gen_enc_loss 24.82701873779297\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 23, disc_loss 10.37238883972168, gen_enc_loss 14.088903427124023\n",
            "50it [01:17,  1.52s/it]epoch 23, disc_loss 10.505707740783691, gen_enc_loss 14.405708312988281\n",
            "100it [02:33,  1.53s/it]epoch 23, disc_loss 11.702199935913086, gen_enc_loss 14.511377334594727\n",
            "150it [03:49,  1.52s/it]epoch 23, disc_loss 11.203484535217285, gen_enc_loss 22.715181350708008\n",
            "200it [05:06,  1.53s/it]epoch 23, disc_loss 9.096923828125, gen_enc_loss 12.424581527709961\n",
            "234it [05:58,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 24, disc_loss 9.96502685546875, gen_enc_loss 11.825681686401367\n",
            "50it [01:17,  1.53s/it]epoch 24, disc_loss 11.06669807434082, gen_enc_loss 11.063970565795898\n",
            "100it [02:33,  1.53s/it]epoch 24, disc_loss 10.976529121398926, gen_enc_loss 8.870461463928223\n",
            "150it [03:50,  1.57s/it]epoch 24, disc_loss 8.617238998413086, gen_enc_loss 10.85301399230957\n",
            "200it [05:06,  1.52s/it]epoch 24, disc_loss 10.8251953125, gen_enc_loss 16.13459587097168\n",
            "234it [05:58,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 25, disc_loss 4.520016193389893, gen_enc_loss 16.814498901367188\n",
            "50it [01:17,  1.51s/it]epoch 25, disc_loss 13.086023330688477, gen_enc_loss 25.20073699951172\n",
            "100it [02:33,  1.54s/it]epoch 25, disc_loss 10.54306411743164, gen_enc_loss 21.37627410888672\n",
            "150it [03:49,  1.52s/it]epoch 25, disc_loss 12.231549263000488, gen_enc_loss 9.407546997070312\n",
            "200it [05:05,  1.52s/it]epoch 25, disc_loss 8.855868339538574, gen_enc_loss 8.984916687011719\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 26, disc_loss 9.868037223815918, gen_enc_loss 13.652755737304688\n",
            "50it [01:17,  1.52s/it]epoch 26, disc_loss 8.874443054199219, gen_enc_loss 24.959293365478516\n",
            "100it [02:33,  1.52s/it]epoch 26, disc_loss 8.550185203552246, gen_enc_loss 16.825225830078125\n",
            "150it [03:49,  1.54s/it]epoch 26, disc_loss 9.532487869262695, gen_enc_loss 8.706499099731445\n",
            "200it [05:06,  1.52s/it]epoch 26, disc_loss 6.536533355712891, gen_enc_loss 9.007043838500977\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 27, disc_loss 10.563558578491211, gen_enc_loss 12.27260684967041\n",
            "50it [01:17,  1.52s/it]epoch 27, disc_loss 11.03079605102539, gen_enc_loss 12.844039916992188\n",
            "100it [02:33,  1.53s/it]epoch 27, disc_loss 13.1973295211792, gen_enc_loss 12.667051315307617\n",
            "150it [03:50,  1.52s/it]epoch 27, disc_loss 10.823126792907715, gen_enc_loss 13.978229522705078\n",
            "200it [05:06,  1.53s/it]epoch 27, disc_loss 7.643811225891113, gen_enc_loss 17.765979766845703\n",
            "234it [05:58,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 28, disc_loss 10.233282089233398, gen_enc_loss 10.948457717895508\n",
            "50it [01:17,  1.54s/it]epoch 28, disc_loss 4.9755859375, gen_enc_loss 7.376801490783691\n",
            "100it [02:33,  1.52s/it]epoch 28, disc_loss 10.298189163208008, gen_enc_loss 16.31080436706543\n",
            "150it [03:50,  1.52s/it]epoch 28, disc_loss 10.857614517211914, gen_enc_loss 7.897683620452881\n",
            "200it [05:06,  1.52s/it]epoch 28, disc_loss 11.144784927368164, gen_enc_loss 9.846179962158203\n",
            "234it [05:57,  1.53s/it]\n",
            "0it [00:00, ?it/s]epoch 29, disc_loss 10.42263412475586, gen_enc_loss 9.317934036254883\n",
            "50it [01:17,  1.52s/it]epoch 29, disc_loss 10.83397102355957, gen_enc_loss 8.762825012207031\n",
            "100it [02:33,  1.52s/it]epoch 29, disc_loss 13.209487915039062, gen_enc_loss 10.947389602661133\n",
            "150it [03:50,  1.52s/it]epoch 29, disc_loss 11.225576400756836, gen_enc_loss 7.851493835449219\n",
            "200it [05:06,  1.52s/it]epoch 29, disc_loss 9.68432331085205, gen_enc_loss 6.846426010131836\n",
            "234it [05:57,  1.53s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifORDCdAjdxY"
      },
      "source": [
        "### Testing\n",
        "\n",
        "Inception Score is ::::::  1.1324967 when 9 epochs\n",
        "\n",
        "A new function is added to Testing phase in which 100 images are generated and saved in \"data/MNIST/infogan/gen_C/\" for different values of C like [1,0,0,0,0,0,0,0,0,0] to see if each C corresponds to a visual feature of the generated numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGhmjzeNyIKf",
        "outputId": "5381eb07-9580-4f90-da1b-188e92b253a0"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"info_gan\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating C gen directory for InfoGAN\n",
            "\r0it [00:00, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "1it [00:05,  5.77s/it]done\n",
            "1it [00:05,  5.80s/it]\n",
            "original images saved\n",
            "creating generated image directory (save one batch\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:01<00:00, 63.3MB/s] \n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/drive/MyDrive/BigBiGAN-PyTorch-main/src/pipeline/pipeline.py:235: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n",
            "___________________________________\n",
            "Inception Score is ::::::  1.1342056\n",
            "___________________________________\n",
            "  5% 14/256 [00:09<02:58,  1.36it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_w5JhfDTHMX"
      },
      "source": [
        "### FID\n",
        "\n",
        "FID:  5.818133444634549"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIjIQkXNRFkJ",
        "outputId": "277cd3db-98b6-4119-d192-eb2e925ce68d"
      },
      "source": [
        "!python -m pytorch_fid \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/org/\" \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sxz/gen/\" --dims 192 --device \"cuda\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:03<00:00, 25.4MB/s]\n",
            "100% 6/6 [01:12<00:00, 12.15s/it]\n",
            "100% 6/6 [01:11<00:00, 11.84s/it]\n",
            "FID:  5.818133444634549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKqbZ6zQGNy1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxfqvul4GrIN",
        "outputId": "25158444-d963-4370-c255-109a13d358c7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0moG9qA9GNwM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ5Lpx6AGNts"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAJbGhKUGNq7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiyWUdTGNnB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkmpWV5uGNBr",
        "outputId": "0a6f4334-1755-48c4-d960-bfeab89c57e8"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 1 --loss_mode \"info_gan\" # --resume 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating model from configuration\n",
            "2021-05-21 15:17:47.695595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]epoch 0, disc_loss 15.332979202270508, gen_enc_loss 8.265162467956543\n",
            "50it [01:54,  2.28s/it]epoch 0, disc_loss 7.582223892211914, gen_enc_loss 15.682806968688965\n",
            "100it [03:48,  2.29s/it]epoch 0, disc_loss 9.860980987548828, gen_enc_loss 16.33121681213379\n",
            "150it [05:42,  2.29s/it]epoch 0, disc_loss 9.2186861038208, gen_enc_loss 17.80141830444336\n",
            "200it [07:37,  2.28s/it]epoch 0, disc_loss 2.5476303100585938, gen_enc_loss 21.89464569091797\n",
            "234it [08:54,  2.29s/it]\n",
            "0it [00:00, ?it/s]epoch 1, disc_loss 4.852934837341309, gen_enc_loss 15.166507720947266\n",
            "50it [02:03,  2.46s/it]epoch 1, disc_loss 6.755472183227539, gen_enc_loss 14.852058410644531\n",
            "100it [04:06,  2.46s/it]epoch 1, disc_loss 2.7409067153930664, gen_enc_loss 13.804495811462402\n",
            "150it [06:08,  2.45s/it]epoch 1, disc_loss 4.441460609436035, gen_enc_loss 13.099180221557617\n",
            "200it [08:11,  2.45s/it]epoch 1, disc_loss 5.541119575500488, gen_enc_loss 14.12408447265625\n",
            "234it [09:34,  2.45s/it]\n",
            "0it [00:00, ?it/s]epoch 2, disc_loss 7.418623924255371, gen_enc_loss 20.92032241821289\n",
            "50it [02:03,  2.45s/it]epoch 2, disc_loss 2.695681095123291, gen_enc_loss 13.666998863220215\n",
            "100it [04:06,  2.48s/it]epoch 2, disc_loss 8.25167179107666, gen_enc_loss 13.633476257324219\n",
            "150it [06:10,  2.47s/it]epoch 2, disc_loss 4.961777687072754, gen_enc_loss 18.379331588745117\n",
            "200it [08:13,  2.46s/it]epoch 2, disc_loss -8.522114753723145, gen_enc_loss 10.39908504486084\n",
            "234it [09:37,  2.47s/it]\n",
            "0it [00:00, ?it/s]epoch 3, disc_loss 1.2593488693237305, gen_enc_loss 10.31180191040039\n",
            "50it [02:04,  2.46s/it]epoch 3, disc_loss 8.236679077148438, gen_enc_loss 31.250442504882812\n",
            "100it [04:07,  2.46s/it]epoch 3, disc_loss 2.3830032348632812, gen_enc_loss 27.59152603149414\n",
            "150it [06:10,  2.45s/it]epoch 3, disc_loss 2.213461399078369, gen_enc_loss 18.910381317138672\n",
            "200it [08:13,  2.49s/it]epoch 3, disc_loss -2.167018175125122, gen_enc_loss 12.918298721313477\n",
            "234it [09:36,  2.47s/it]\n",
            "0it [00:00, ?it/s]epoch 4, disc_loss -2.6924610137939453, gen_enc_loss 32.01946258544922\n",
            "50it [02:03,  2.46s/it]epoch 4, disc_loss -0.22413158416748047, gen_enc_loss 10.104934692382812\n",
            "100it [04:06,  2.46s/it]epoch 4, disc_loss 7.807156562805176, gen_enc_loss 26.114648818969727\n",
            "150it [06:09,  2.45s/it]epoch 4, disc_loss 1.940147876739502, gen_enc_loss 16.26770782470703\n",
            "200it [08:12,  2.46s/it]epoch 4, disc_loss 7.465107440948486, gen_enc_loss 34.590999603271484\n",
            "234it [09:35,  2.46s/it]\n",
            "0it [00:00, ?it/s]epoch 5, disc_loss 1.9581027030944824, gen_enc_loss 17.046371459960938\n",
            "50it [02:03,  2.44s/it]epoch 5, disc_loss -0.7198114395141602, gen_enc_loss 20.36135482788086\n",
            "100it [04:06,  2.45s/it]epoch 5, disc_loss 4.651612281799316, gen_enc_loss 12.885261535644531\n",
            "150it [06:08,  2.45s/it]epoch 5, disc_loss 3.620009660720825, gen_enc_loss 17.7293643951416\n",
            "200it [08:11,  2.45s/it]epoch 5, disc_loss 4.671518802642822, gen_enc_loss 9.274025917053223\n",
            "234it [09:34,  2.45s/it]\n",
            "0it [00:00, ?it/s]epoch 6, disc_loss 0.010085105895996094, gen_enc_loss 17.24297332763672\n",
            "50it [02:03,  2.44s/it]epoch 6, disc_loss 5.962284088134766, gen_enc_loss 15.630282402038574\n",
            "100it [04:05,  2.44s/it]epoch 6, disc_loss 1.0424838066101074, gen_enc_loss 19.95166015625\n",
            "150it [06:07,  2.45s/it]epoch 6, disc_loss 6.210484504699707, gen_enc_loss 9.562503814697266\n",
            "200it [08:09,  2.45s/it]epoch 6, disc_loss 2.0205283164978027, gen_enc_loss 20.990507125854492\n",
            "234it [09:32,  2.45s/it]\n",
            "0it [00:00, ?it/s]epoch 7, disc_loss 8.724891662597656, gen_enc_loss 22.620187759399414\n",
            "50it [02:02,  2.44s/it]epoch 7, disc_loss 2.554839611053467, gen_enc_loss 25.873828887939453\n",
            "100it [04:04,  2.44s/it]epoch 7, disc_loss -1.450124740600586, gen_enc_loss 18.58754539489746\n",
            "150it [06:07,  2.45s/it]epoch 7, disc_loss 0.1804642677307129, gen_enc_loss 12.316434860229492\n",
            "200it [08:09,  2.46s/it]epoch 7, disc_loss -3.1349382400512695, gen_enc_loss 16.587324142456055\n",
            "234it [09:32,  2.45s/it]\n",
            "0it [00:00, ?it/s]epoch 8, disc_loss 5.005181312561035, gen_enc_loss 12.737252235412598\n",
            "50it [02:03,  2.43s/it]epoch 8, disc_loss 3.6536428928375244, gen_enc_loss 23.684444427490234\n",
            "100it [04:05,  2.44s/it]epoch 8, disc_loss 2.6542930603027344, gen_enc_loss 25.776691436767578\n",
            "150it [06:07,  2.44s/it]epoch 8, disc_loss 2.033356189727783, gen_enc_loss 21.032562255859375\n",
            "200it [08:08,  2.44s/it]epoch 8, disc_loss 2.840313196182251, gen_enc_loss 10.274431228637695\n",
            "234it [09:31,  2.44s/it]\n",
            "0it [00:00, ?it/s]epoch 9, disc_loss 1.606884479522705, gen_enc_loss 14.894948959350586\n",
            "50it [02:03,  2.45s/it]epoch 9, disc_loss 6.386684417724609, gen_enc_loss 13.721287727355957\n",
            "58it [02:22,  2.44s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIfIj6WNIIAa",
        "outputId": "693d873b-4ed9-4071-85bf-9af7b46e19c7"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"info_gan\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\", line 106, in <module>\n",
            "    run_experiments()\n",
            "  File \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\", line 44, in run_experiments\n",
            "    run_experiment(config)\n",
            "  File \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\", line 74, in run_experiment\n",
            "    config=config)\n",
            "  File \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/src/pipeline/pipeline.py\", line 384, in from_checkpoint\n",
            "    checkpoint = torch.load(checkpoint_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 585, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 242, in __init__\n",
            "    super(_open_zipfile_reader, self).__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: [enforce fail at inline_container.cc:145] . PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRHB3OxqfaCb"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/all/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/all/encoded/test.csv\")\n",
        "\n",
        "train_y, train_X = train_df.loc[:, \"0\"], train_df.loc[:, \"1\":\"100\"]\n",
        "test_y, test_X = test_df.loc[:, \"0\"], test_df.loc[:, \"1\":\"100\"]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(train_X, train_y)\n",
        "neigh.score(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ-tRbsAzWo-"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/all/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/all/encoded/test.csv\")\n",
        "\n",
        "# Jobs are labels\n",
        "jobs = train_df.loc[:, \"0\"]\n",
        "# workers are predicted C in infoGAN\n",
        "workers = train_df.loc[:, \"1\":\"10\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}