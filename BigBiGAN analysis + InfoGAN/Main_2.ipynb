{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADL_HW2_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZzhE4086A81c",
        "RWk238PqBPmj",
        "RztjY9D-Ba5M",
        "KjRTkqpXCo80",
        "S4cJFiRPPdP6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQYTPp2PB83M"
      },
      "source": [
        "# Initial stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyjB-O24BcYw",
        "outputId": "359d8797-c323-477c-ae7d-753e078fda31"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV0bD2OVAUa9",
        "outputId": "c09b13a0-9ad4-44d8-ba8f-77e59896fe70"
      },
      "source": [
        "pip install pytorch-fid"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading https://files.pythonhosted.org/packages/93/54/49dc21a5ee774af0390813c3cf66af57af0a31ab22ba0c2ac02cdddeb755/pytorch-fid-0.2.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->pytorch-fid) (3.7.4.3)\n",
            "Building wheels for collected packages: pytorch-fid\n",
            "  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.0-cp37-none-any.whl size=10547 sha256=000e22d1334f4a0693893c840478a93d9994f93f4fe3e2312a8f92d9fb255bb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/36/3c/4f3fb256f62d24bef52636f66f21667bc21caa637ce92f0e53\n",
            "Successfully built pytorch-fid\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs6CWT_aKRhF",
        "outputId": "a0a2c8d9-b320-4777-90c1-fd9437c6f13f"
      },
      "source": [
        "!git clone https://github.com/RKorzeniowski/BigBiGAN-PyTorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BigBiGAN-PyTorch'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 57 (delta 18), reused 51 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghWXIulXCCht"
      },
      "source": [
        "# Continued of Loss modes:\n",
        "\n",
        "This is a second notebook following the first notebook and contains 2 remaining \n",
        "loss modes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23JqMIa3CWIr"
      },
      "source": [
        "## no SX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzhE4086A81c"
      },
      "source": [
        "### Train\n",
        "\n",
        "--loss_mode: \"no_sx\"\n",
        "\n",
        "--train: 1\n",
        "\n",
        "epoch 9, disc_loss 1.564275860786438, gen_enc_loss 0.7596995830535889"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hph_0-SSGcPa",
        "outputId": "78e4a8c8-d651-4ac1-9211-a7126e71c670"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 1 --loss_mode \"no_sx\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-13 15:59:05.212468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]epoch 0, disc_loss 1.9837738275527954, gen_enc_loss 0.04402796924114227\n",
            "50it [00:49,  1.03it/s]epoch 0, disc_loss 1.0065821409225464, gen_enc_loss 1.7737467288970947\n",
            "100it [01:38,  1.01it/s]epoch 0, disc_loss 1.0079492330551147, gen_enc_loss 1.609933853149414\n",
            "150it [02:28,  1.01it/s]epoch 0, disc_loss 1.1134612560272217, gen_enc_loss 1.4438576698303223\n",
            "200it [03:17,  1.00it/s]epoch 0, disc_loss 1.3377487659454346, gen_enc_loss 1.401383399963379\n",
            "234it [03:51,  1.01it/s]\n",
            "0it [00:00, ?it/s]epoch 1, disc_loss 1.4414640665054321, gen_enc_loss 1.2324106693267822\n",
            "50it [00:57,  1.10s/it]epoch 1, disc_loss 1.3864318132400513, gen_enc_loss 0.827826976776123\n",
            "100it [01:53,  1.12s/it]epoch 1, disc_loss 1.306912899017334, gen_enc_loss 1.0106557607650757\n",
            "150it [02:49,  1.11s/it]epoch 1, disc_loss 1.3184442520141602, gen_enc_loss 0.9567477703094482\n",
            "200it [03:45,  1.11s/it]epoch 1, disc_loss 1.3730063438415527, gen_enc_loss 0.6869492530822754\n",
            "234it [04:23,  1.13s/it]\n",
            "0it [00:00, ?it/s]epoch 2, disc_loss 1.420530080795288, gen_enc_loss 0.8471118211746216\n",
            "50it [00:56,  1.12s/it]epoch 2, disc_loss 1.4887133836746216, gen_enc_loss 0.6719116568565369\n",
            "100it [01:52,  1.12s/it]epoch 2, disc_loss 1.521327018737793, gen_enc_loss 0.7533403038978577\n",
            "150it [02:48,  1.12s/it]epoch 2, disc_loss 1.501699447631836, gen_enc_loss 0.6977654099464417\n",
            "200it [03:43,  1.11s/it]epoch 2, disc_loss 1.4428431987762451, gen_enc_loss 0.7841377258300781\n",
            "234it [04:21,  1.12s/it]\n",
            "0it [00:00, ?it/s]epoch 3, disc_loss 1.4883884191513062, gen_enc_loss 0.7006698250770569\n",
            "50it [00:57,  1.15s/it]epoch 3, disc_loss 1.448477029800415, gen_enc_loss 0.7525883316993713\n",
            "100it [01:55,  1.15s/it]epoch 3, disc_loss 1.464167594909668, gen_enc_loss 0.7313013076782227\n",
            "150it [02:52,  1.13s/it]epoch 3, disc_loss 1.5353100299835205, gen_enc_loss 0.6003545522689819\n",
            "200it [03:49,  1.12s/it]epoch 3, disc_loss 1.4723820686340332, gen_enc_loss 0.820196270942688\n",
            "234it [04:27,  1.14s/it]\n",
            "0it [00:00, ?it/s]epoch 4, disc_loss 1.5531160831451416, gen_enc_loss 0.6922454833984375\n",
            "50it [00:57,  1.13s/it]epoch 4, disc_loss 1.461719036102295, gen_enc_loss 0.8600708246231079\n",
            "100it [01:54,  1.13s/it]epoch 4, disc_loss 1.525479793548584, gen_enc_loss 0.7125740051269531\n",
            "150it [02:50,  1.14s/it]epoch 4, disc_loss 1.4828481674194336, gen_enc_loss 0.8225533366203308\n",
            "200it [03:47,  1.14s/it]epoch 4, disc_loss 1.594961404800415, gen_enc_loss 0.6033509969711304\n",
            "234it [04:25,  1.14s/it]\n",
            "0it [00:00, ?it/s]epoch 5, disc_loss 1.6023937463760376, gen_enc_loss 0.6250200271606445\n",
            "50it [00:57,  1.14s/it]epoch 5, disc_loss 1.5406365394592285, gen_enc_loss 0.8525245189666748\n",
            "100it [01:54,  1.20s/it]epoch 5, disc_loss 1.5306413173675537, gen_enc_loss 0.6595706939697266\n",
            "150it [02:50,  1.13s/it]epoch 5, disc_loss 1.551291584968567, gen_enc_loss 0.8651261925697327\n",
            "200it [03:47,  1.13s/it]epoch 5, disc_loss 1.65328049659729, gen_enc_loss 0.526441216468811\n",
            "234it [04:25,  1.13s/it]\n",
            "0it [00:00, ?it/s]epoch 6, disc_loss 1.6226640939712524, gen_enc_loss 0.6743844747543335\n",
            "50it [00:58,  1.14s/it]epoch 6, disc_loss 1.7124061584472656, gen_enc_loss 0.5338603854179382\n",
            "100it [01:54,  1.13s/it]epoch 6, disc_loss 1.74080228805542, gen_enc_loss 0.45502638816833496\n",
            "150it [02:51,  1.18s/it]epoch 6, disc_loss 1.5477402210235596, gen_enc_loss 0.7351361513137817\n",
            "200it [03:48,  1.14s/it]epoch 6, disc_loss 1.6729379892349243, gen_enc_loss 0.5165144205093384\n",
            "234it [04:27,  1.14s/it]\n",
            "0it [00:00, ?it/s]epoch 7, disc_loss 1.5201858282089233, gen_enc_loss 0.8106868863105774\n",
            "50it [00:57,  1.13s/it]epoch 7, disc_loss 1.7397397756576538, gen_enc_loss 0.4380320906639099\n",
            "100it [01:54,  1.13s/it]epoch 7, disc_loss 1.6482712030410767, gen_enc_loss 0.6244720816612244\n",
            "150it [02:50,  1.13s/it]epoch 7, disc_loss 1.6727559566497803, gen_enc_loss 0.532185971736908\n",
            "200it [03:47,  1.13s/it]epoch 7, disc_loss 1.7038495540618896, gen_enc_loss 0.572739839553833\n",
            "234it [04:25,  1.14s/it]\n",
            "0it [00:00, ?it/s]epoch 8, disc_loss 1.5809814929962158, gen_enc_loss 0.7161439657211304\n",
            "50it [00:58,  1.14s/it]epoch 8, disc_loss 1.5683364868164062, gen_enc_loss 0.6966812610626221\n",
            "100it [01:54,  1.12s/it]epoch 8, disc_loss 1.7488404512405396, gen_enc_loss 0.49475300312042236\n",
            "150it [02:51,  1.14s/it]epoch 8, disc_loss 1.680620551109314, gen_enc_loss 0.45133236050605774\n",
            "200it [03:47,  1.13s/it]epoch 8, disc_loss 1.6703832149505615, gen_enc_loss 0.4659983217716217\n",
            "234it [04:26,  1.14s/it]\n",
            "0it [00:00, ?it/s]epoch 9, disc_loss 1.564275860786438, gen_enc_loss 0.7596995830535889\n",
            "50it [00:57,  1.15s/it]epoch 9, disc_loss 1.659574031829834, gen_enc_loss 0.6915899515151978\n",
            "100it [01:54,  1.13s/it]epoch 9, disc_loss 1.498903751373291, gen_enc_loss 0.6062503457069397\n",
            "150it [02:50,  1.13s/it]epoch 9, disc_loss 1.679796576499939, gen_enc_loss 0.5313008427619934\n",
            "200it [03:47,  1.13s/it]epoch 9, disc_loss 1.5598081350326538, gen_enc_loss 0.6619247198104858\n",
            "234it [04:25,  1.14s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWk238PqBPmj"
      },
      "source": [
        "### Testing\n",
        "\n",
        "--train: 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMLxRz954lRM",
        "outputId": "52821b76-da02-4ef5-f835-52aa841fe4e3"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"no_sx\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original images saved\n",
            "creating generated image directory (save one batch\n",
            "0it [00:00, ?it/s]\n",
            "  0% 0/256 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 1/256 [00:00<00:50,  5.10it/s]\u001b[A\n",
            "  1% 3/256 [00:00<00:40,  6.23it/s]\u001b[A\n",
            "  2% 4/256 [00:00<00:35,  7.03it/s]\u001b[A\n",
            "  2% 5/256 [00:00<00:34,  7.20it/s]\u001b[A\n",
            "  2% 6/256 [00:00<00:34,  7.16it/s]\u001b[A\n",
            "  3% 7/256 [00:00<00:36,  6.89it/s]\u001b[A\n",
            "  3% 8/256 [00:01<00:37,  6.55it/s]\u001b[A\n",
            "  4% 9/256 [00:01<00:40,  6.03it/s]\u001b[A\n",
            "  4% 10/256 [00:01<00:44,  5.53it/s]\u001b[A\n",
            "  4% 11/256 [00:01<00:47,  5.13it/s]\u001b[A\n",
            "  5% 12/256 [00:01<00:52,  4.68it/s]\u001b[A\n",
            "  5% 13/256 [00:02<00:56,  4.30it/s]\u001b[A\n",
            "  5% 14/256 [00:02<01:01,  3.93it/s]\u001b[A\n",
            "  6% 15/256 [00:02<01:05,  3.70it/s]\u001b[A\n",
            "  6% 16/256 [00:03<01:08,  3.51it/s]\u001b[A\n",
            "  7% 17/256 [00:03<01:12,  3.28it/s]\u001b[A\n",
            "  7% 18/256 [00:03<01:16,  3.12it/s]\u001b[A\n",
            "  7% 19/256 [00:04<01:35,  2.48it/s]\u001b[A\n",
            "  8% 20/256 [00:04<01:34,  2.50it/s]\u001b[A\n",
            "  8% 21/256 [00:05<01:35,  2.47it/s]\u001b[A\n",
            "  9% 22/256 [00:05<01:36,  2.43it/s]\u001b[A\n",
            "  9% 23/256 [00:06<01:38,  2.37it/s]\u001b[A\n",
            "  9% 24/256 [00:06<01:42,  2.26it/s]\u001b[A\n",
            " 10% 25/256 [00:07<01:45,  2.19it/s]\u001b[A\n",
            " 10% 26/256 [00:07<01:51,  2.07it/s]\u001b[A\n",
            " 11% 27/256 [00:08<01:53,  2.02it/s]\u001b[A\n",
            " 11% 28/256 [00:08<01:56,  1.96it/s]\u001b[A\n",
            " 11% 29/256 [00:09<01:59,  1.90it/s]\u001b[A\n",
            " 12% 30/256 [00:09<02:04,  1.81it/s]\u001b[A\n",
            " 12% 31/256 [00:10<02:09,  1.74it/s]\u001b[A\n",
            " 12% 32/256 [00:11<02:12,  1.70it/s]\u001b[A\n",
            " 13% 33/256 [00:11<02:14,  1.66it/s]\u001b[A\n",
            " 13% 34/256 [00:12<02:18,  1.60it/s]\u001b[A\n",
            " 14% 35/256 [00:13<02:19,  1.58it/s]\u001b[A\n",
            " 14% 36/256 [00:13<02:24,  1.52it/s]\u001b[A\n",
            " 14% 37/256 [00:14<02:28,  1.48it/s]\u001b[A\n",
            " 15% 38/256 [00:15<02:30,  1.45it/s]\u001b[A\n",
            " 15% 39/256 [00:16<02:36,  1.38it/s]\u001b[A\n",
            " 16% 40/256 [00:16<02:40,  1.35it/s]\u001b[A\n",
            " 16% 41/256 [00:17<02:43,  1.32it/s]\u001b[A\n",
            " 16% 42/256 [00:18<02:47,  1.28it/s]\u001b[A\n",
            " 17% 43/256 [00:19<02:48,  1.26it/s]\u001b[A\n",
            " 17% 44/256 [00:20<02:55,  1.21it/s]\u001b[A\n",
            " 18% 45/256 [00:21<03:01,  1.16it/s]\u001b[A\n",
            " 18% 46/256 [00:22<03:07,  1.12it/s]\u001b[A\n",
            " 18% 47/256 [00:23<03:11,  1.09it/s]\u001b[A\n",
            " 19% 48/256 [00:24<03:16,  1.06it/s]\u001b[A\n",
            " 19% 49/256 [00:25<03:20,  1.03it/s]\u001b[A\n",
            " 20% 50/256 [00:26<03:21,  1.02it/s]\u001b[A\n",
            " 20% 51/256 [00:27<03:24,  1.00it/s]\u001b[A\n",
            " 20% 52/256 [00:28<03:27,  1.02s/it]\u001b[A\n",
            " 21% 53/256 [00:29<03:27,  1.02s/it]\u001b[A\n",
            " 21% 54/256 [00:30<03:28,  1.03s/it]\u001b[A\n",
            " 21% 55/256 [00:31<03:29,  1.04s/it]\u001b[A\n",
            " 22% 56/256 [00:32<03:32,  1.06s/it]\u001b[A\n",
            " 22% 57/256 [00:33<03:34,  1.08s/it]\u001b[A\n",
            " 23% 58/256 [00:34<03:35,  1.09s/it]\u001b[A\n",
            " 23% 59/256 [00:35<03:40,  1.12s/it]\u001b[A\n",
            " 23% 60/256 [00:37<03:44,  1.15s/it]\u001b[A\n",
            " 24% 61/256 [00:38<03:47,  1.17s/it]\u001b[A\n",
            " 24% 62/256 [00:39<03:49,  1.18s/it]\u001b[A\n",
            " 25% 63/256 [00:40<03:50,  1.19s/it]\u001b[A\n",
            " 25% 64/256 [00:42<03:51,  1.21s/it]\u001b[A\n",
            " 25% 65/256 [00:43<03:55,  1.23s/it]\u001b[A\n",
            " 26% 66/256 [00:44<03:59,  1.26s/it]\u001b[A\n",
            " 26% 67/256 [00:45<04:03,  1.29s/it]\u001b[A\n",
            " 27% 68/256 [00:47<04:03,  1.29s/it]\u001b[A\n",
            " 27% 69/256 [00:48<04:06,  1.32s/it]\u001b[A\n",
            " 27% 70/256 [00:50<04:07,  1.33s/it]\u001b[A\n",
            " 28% 71/256 [00:51<04:11,  1.36s/it]\u001b[A\n",
            " 28% 72/256 [00:52<04:12,  1.37s/it]\u001b[A\n",
            " 29% 73/256 [00:54<04:13,  1.38s/it]\u001b[A\n",
            " 29% 74/256 [00:55<04:13,  1.39s/it]\u001b[A\n",
            " 29% 75/256 [00:57<04:16,  1.42s/it]\u001b[A\n",
            " 30% 76/256 [00:58<04:18,  1.44s/it]\u001b[A\n",
            " 30% 77/256 [01:00<04:21,  1.46s/it]\u001b[A\n",
            " 30% 78/256 [01:01<04:23,  1.48s/it]\u001b[A\n",
            " 31% 79/256 [01:03<04:26,  1.50s/it]\u001b[A\n",
            " 31% 80/256 [01:04<04:25,  1.51s/it]\u001b[A\n",
            " 32% 81/256 [01:06<04:26,  1.52s/it]\u001b[A\n",
            " 32% 82/256 [01:07<04:29,  1.55s/it]\u001b[A\n",
            " 32% 83/256 [01:09<04:31,  1.57s/it]\u001b[A\n",
            " 33% 84/256 [01:11<04:34,  1.59s/it]\u001b[A\n",
            " 33% 85/256 [01:12<04:35,  1.61s/it]\u001b[A\n",
            " 34% 86/256 [01:14<04:36,  1.63s/it]\u001b[A\n",
            " 34% 87/256 [01:16<04:37,  1.64s/it]\u001b[A\n",
            " 34% 88/256 [01:17<04:38,  1.66s/it]\u001b[A\n",
            " 35% 89/256 [01:19<04:41,  1.68s/it]\u001b[A\n",
            " 35% 90/256 [01:21<04:43,  1.71s/it]\u001b[A\n",
            " 36% 91/256 [01:23<04:44,  1.72s/it]\u001b[A\n",
            " 36% 92/256 [01:24<04:47,  1.75s/it]\u001b[A\n",
            " 36% 93/256 [01:26<04:50,  1.78s/it]\u001b[A\n",
            " 37% 94/256 [01:28<04:53,  1.81s/it]\u001b[A\n",
            " 37% 95/256 [01:30<04:52,  1.82s/it]\u001b[A\n",
            " 38% 96/256 [01:32<04:52,  1.83s/it]\u001b[A\n",
            " 38% 97/256 [01:34<04:54,  1.85s/it]\u001b[A\n",
            " 38% 98/256 [01:36<04:54,  1.87s/it]\u001b[A\n",
            " 39% 99/256 [01:38<04:54,  1.87s/it]\u001b[A\n",
            " 39% 100/256 [01:40<04:55,  1.89s/it]\u001b[A\n",
            " 39% 101/256 [01:41<04:56,  1.91s/it]\u001b[A\n",
            " 40% 102/256 [01:43<04:58,  1.94s/it]\u001b[A\n",
            " 40% 103/256 [01:46<05:00,  1.96s/it]\u001b[A\n",
            " 41% 104/256 [01:48<04:59,  1.97s/it]\u001b[A\n",
            " 41% 105/256 [01:50<04:59,  1.98s/it]\u001b[A\n",
            " 41% 106/256 [01:52<05:01,  2.01s/it]\u001b[A\n",
            " 42% 107/256 [01:54<05:02,  2.03s/it]\u001b[A\n",
            " 42% 108/256 [01:56<05:06,  2.07s/it]\u001b[A\n",
            " 43% 109/256 [01:58<05:07,  2.09s/it]\u001b[A\n",
            " 43% 110/256 [02:00<05:06,  2.10s/it]\u001b[A\n",
            " 43% 111/256 [02:02<05:06,  2.12s/it]\u001b[A\n",
            " 44% 112/256 [02:04<05:07,  2.13s/it]\u001b[A\n",
            " 44% 113/256 [02:07<05:08,  2.16s/it]\u001b[A\n",
            " 45% 114/256 [02:09<05:07,  2.17s/it]\u001b[A\n",
            " 45% 115/256 [02:11<05:05,  2.17s/it]\u001b[A\n",
            " 45% 116/256 [02:13<05:04,  2.18s/it]\u001b[A\n",
            " 46% 117/256 [02:15<05:04,  2.19s/it]\u001b[A\n",
            " 46% 118/256 [02:18<05:05,  2.21s/it]\u001b[A\n",
            " 46% 119/256 [02:20<05:05,  2.23s/it]\u001b[A\n",
            " 47% 120/256 [02:22<05:05,  2.25s/it]\u001b[A\n",
            " 47% 121/256 [02:25<05:06,  2.27s/it]\u001b[A\n",
            " 48% 122/256 [02:27<05:07,  2.30s/it]\u001b[A\n",
            " 48% 123/256 [02:29<05:09,  2.32s/it]\u001b[A\n",
            " 48% 124/256 [02:32<05:08,  2.34s/it]\u001b[A\n",
            " 49% 125/256 [02:34<05:11,  2.38s/it]\u001b[A\n",
            " 49% 126/256 [02:37<05:13,  2.41s/it]\u001b[A\n",
            " 50% 127/256 [02:39<05:10,  2.41s/it]\u001b[A\n",
            " 50% 128/256 [02:42<05:10,  2.43s/it]\u001b[A\n",
            " 50% 129/256 [02:44<05:11,  2.45s/it]\u001b[A\n",
            " 51% 130/256 [02:46<05:09,  2.46s/it]\u001b[A\n",
            " 51% 131/256 [02:49<05:10,  2.49s/it]\u001b[A\n",
            " 52% 132/256 [02:52<05:12,  2.52s/it]\u001b[A\n",
            " 52% 133/256 [02:54<05:10,  2.53s/it]\u001b[A\n",
            " 52% 134/256 [02:57<05:12,  2.56s/it]\u001b[A\n",
            " 53% 135/256 [02:59<05:11,  2.58s/it]\u001b[A\n",
            " 53% 136/256 [03:02<05:11,  2.60s/it]\u001b[A\n",
            " 54% 137/256 [03:05<05:11,  2.62s/it]\u001b[A\n",
            " 54% 138/256 [03:07<05:10,  2.64s/it]\u001b[A\n",
            " 54% 139/256 [03:10<05:10,  2.65s/it]\u001b[A\n",
            " 55% 140/256 [03:13<05:10,  2.68s/it]\u001b[A\n",
            " 55% 141/256 [03:16<05:08,  2.69s/it]\u001b[A\n",
            " 55% 142/256 [03:18<05:06,  2.69s/it]\u001b[A\n",
            " 56% 143/256 [03:21<05:05,  2.70s/it]\u001b[A\n",
            " 56% 144/256 [03:24<05:03,  2.71s/it]\u001b[A\n",
            " 57% 145/256 [03:26<05:01,  2.72s/it]\u001b[A\n",
            " 57% 146/256 [03:29<04:57,  2.71s/it]\u001b[A\n",
            " 57% 147/256 [03:32<04:54,  2.70s/it]\u001b[A\n",
            " 58% 148/256 [03:35<04:53,  2.72s/it]\u001b[A\n",
            " 58% 149/256 [03:37<04:51,  2.72s/it]\u001b[A\n",
            " 59% 150/256 [03:40<04:49,  2.73s/it]\u001b[A\n",
            " 59% 151/256 [03:43<04:46,  2.73s/it]\u001b[A\n",
            " 59% 152/256 [03:46<04:46,  2.76s/it]\u001b[A\n",
            " 60% 153/256 [03:49<04:47,  2.79s/it]\u001b[A\n",
            " 60% 154/256 [03:51<04:47,  2.82s/it]\u001b[A\n",
            " 61% 155/256 [03:54<04:46,  2.84s/it]\u001b[A\n",
            " 61% 156/256 [03:57<04:47,  2.88s/it]\u001b[A\n",
            " 61% 157/256 [04:00<04:47,  2.91s/it]\u001b[A\n",
            " 62% 158/256 [04:03<04:46,  2.93s/it]\u001b[A\n",
            " 62% 159/256 [04:06<04:45,  2.94s/it]\u001b[A\n",
            " 62% 160/256 [04:09<04:45,  2.97s/it]\u001b[A\n",
            " 63% 161/256 [04:12<04:43,  2.99s/it]\u001b[A\n",
            " 63% 162/256 [04:15<04:43,  3.01s/it]\u001b[A\n",
            " 64% 163/256 [04:18<04:42,  3.04s/it]\u001b[A\n",
            " 64% 164/256 [04:21<04:39,  3.04s/it]\u001b[A\n",
            " 64% 165/256 [04:25<04:37,  3.05s/it]\u001b[A\n",
            " 65% 166/256 [04:28<04:35,  3.06s/it]\u001b[A\n",
            " 65% 167/256 [04:31<04:34,  3.08s/it]\u001b[A\n",
            " 66% 168/256 [04:34<04:32,  3.09s/it]\u001b[A\n",
            " 66% 169/256 [04:37<04:31,  3.12s/it]\u001b[A\n",
            " 66% 170/256 [04:40<04:29,  3.14s/it]\u001b[A\n",
            " 67% 171/256 [04:43<04:27,  3.15s/it]\u001b[A\n",
            " 67% 172/256 [04:47<04:27,  3.18s/it]\u001b[A\n",
            " 68% 173/256 [04:50<04:25,  3.19s/it]\u001b[A\n",
            " 68% 174/256 [04:53<04:22,  3.20s/it]\u001b[A\n",
            " 68% 175/256 [04:56<04:20,  3.22s/it]\u001b[A\n",
            " 69% 176/256 [05:00<04:17,  3.22s/it]\u001b[A\n",
            " 69% 177/256 [05:03<04:15,  3.24s/it]\u001b[A\n",
            " 70% 178/256 [05:06<04:14,  3.26s/it]\u001b[A\n",
            " 70% 179/256 [05:09<04:11,  3.26s/it]\u001b[A\n",
            " 70% 180/256 [05:13<04:08,  3.27s/it]\u001b[A\n",
            " 71% 181/256 [05:16<04:06,  3.29s/it]\u001b[A\n",
            " 71% 182/256 [05:19<04:06,  3.33s/it]\u001b[A\n",
            " 71% 183/256 [05:23<04:04,  3.35s/it]\u001b[A\n",
            " 72% 184/256 [05:26<04:01,  3.36s/it]\u001b[A\n",
            " 72% 185/256 [05:30<03:59,  3.37s/it]\u001b[A\n",
            " 73% 186/256 [05:33<03:56,  3.38s/it]\u001b[A\n",
            " 73% 187/256 [05:36<03:54,  3.40s/it]\u001b[A\n",
            " 73% 188/256 [05:40<03:52,  3.42s/it]\u001b[A\n",
            " 74% 189/256 [05:43<03:49,  3.43s/it]\u001b[A\n",
            " 74% 190/256 [05:47<03:48,  3.46s/it]\u001b[A\n",
            " 75% 191/256 [05:51<03:47,  3.50s/it]\u001b[A\n",
            " 75% 192/256 [05:54<03:45,  3.52s/it]\u001b[A\n",
            " 75% 193/256 [05:58<03:43,  3.55s/it]\u001b[A\n",
            " 76% 194/256 [06:01<03:41,  3.57s/it]\u001b[A\n",
            " 76% 195/256 [06:05<03:38,  3.58s/it]\u001b[A\n",
            " 77% 196/256 [06:09<03:35,  3.59s/it]\u001b[A\n",
            " 77% 197/256 [06:12<03:33,  3.62s/it]\u001b[A\n",
            " 77% 198/256 [06:16<03:30,  3.63s/it]\u001b[A\n",
            " 78% 199/256 [06:20<03:29,  3.67s/it]\u001b[A\n",
            " 78% 200/256 [06:23<03:26,  3.69s/it]\u001b[A\n",
            " 79% 201/256 [06:27<03:26,  3.75s/it]\u001b[A\n",
            " 79% 202/256 [06:31<03:22,  3.75s/it]\u001b[A\n",
            " 79% 203/256 [06:35<03:19,  3.76s/it]\u001b[A\n",
            " 80% 204/256 [06:39<03:16,  3.78s/it]\u001b[A\n",
            " 80% 205/256 [06:42<03:13,  3.80s/it]\u001b[A\n",
            " 80% 206/256 [06:46<03:10,  3.82s/it]\u001b[A\n",
            " 81% 207/256 [06:50<03:07,  3.82s/it]\u001b[A\n",
            " 81% 208/256 [06:54<03:04,  3.85s/it]\u001b[A\n",
            " 82% 209/256 [06:58<03:02,  3.88s/it]\u001b[A\n",
            " 82% 210/256 [07:02<02:58,  3.89s/it]\u001b[A\n",
            " 82% 211/256 [07:06<02:54,  3.88s/it]\u001b[A\n",
            " 83% 212/256 [07:10<02:50,  3.88s/it]\u001b[A\n",
            " 83% 213/256 [07:14<02:46,  3.88s/it]\u001b[A\n",
            " 84% 214/256 [07:18<02:43,  3.90s/it]\u001b[A\n",
            " 84% 215/256 [07:22<02:40,  3.93s/it]\u001b[A\n",
            " 84% 216/256 [07:26<02:38,  3.96s/it]\u001b[A\n",
            " 85% 217/256 [07:30<02:34,  3.97s/it]\u001b[A\n",
            " 85% 218/256 [07:34<02:31,  3.98s/it]\u001b[A\n",
            " 86% 219/256 [07:38<02:28,  4.01s/it]\u001b[A\n",
            " 86% 220/256 [07:42<02:25,  4.04s/it]\u001b[A\n",
            " 86% 221/256 [07:46<02:22,  4.06s/it]\u001b[A\n",
            " 87% 222/256 [07:50<02:18,  4.08s/it]\u001b[A\n",
            " 87% 223/256 [07:54<02:15,  4.11s/it]\u001b[A\n",
            " 88% 224/256 [07:58<02:12,  4.14s/it]\u001b[A\n",
            " 88% 225/256 [08:03<02:09,  4.17s/it]\u001b[A\n",
            " 88% 226/256 [08:07<02:05,  4.19s/it]\u001b[A\n",
            " 89% 227/256 [08:11<02:02,  4.21s/it]\u001b[A\n",
            " 89% 228/256 [08:15<01:58,  4.24s/it]\u001b[A\n",
            " 89% 229/256 [08:20<01:54,  4.25s/it]\u001b[A\n",
            " 90% 230/256 [08:24<01:50,  4.24s/it]\u001b[A\n",
            " 90% 231/256 [08:28<01:46,  4.24s/it]\u001b[A\n",
            " 91% 232/256 [08:32<01:41,  4.25s/it]\u001b[A\n",
            " 91% 233/256 [08:37<01:37,  4.25s/it]\u001b[A\n",
            " 91% 234/256 [08:41<01:34,  4.28s/it]\u001b[A\n",
            " 92% 235/256 [08:45<01:30,  4.30s/it]\u001b[A\n",
            " 92% 236/256 [08:50<01:26,  4.31s/it]\u001b[A\n",
            " 93% 237/256 [08:54<01:22,  4.34s/it]\u001b[A\n",
            " 93% 238/256 [08:59<01:18,  4.37s/it]\u001b[A\n",
            " 93% 239/256 [09:03<01:14,  4.37s/it]\u001b[A\n",
            " 94% 240/256 [09:07<01:10,  4.40s/it]\u001b[A\n",
            " 94% 241/256 [09:12<01:06,  4.42s/it]\u001b[A\n",
            " 95% 242/256 [09:16<01:01,  4.42s/it]\u001b[A\n",
            " 95% 243/256 [09:21<00:57,  4.44s/it]\u001b[A\n",
            " 95% 244/256 [09:25<00:53,  4.48s/it]\u001b[A\n",
            " 96% 245/256 [09:30<00:49,  4.52s/it]\u001b[A\n",
            " 96% 246/256 [09:34<00:45,  4.52s/it]\u001b[A\n",
            " 96% 247/256 [09:39<00:40,  4.54s/it]\u001b[A\n",
            " 97% 248/256 [09:44<00:36,  4.59s/it]\u001b[A\n",
            " 97% 249/256 [09:48<00:32,  4.62s/it]\u001b[A\n",
            " 98% 250/256 [09:53<00:27,  4.62s/it]\u001b[A\n",
            " 98% 251/256 [09:58<00:23,  4.65s/it]\u001b[A\n",
            " 98% 252/256 [10:02<00:18,  4.64s/it]\u001b[A\n",
            " 99% 253/256 [10:07<00:13,  4.64s/it]\u001b[A\n",
            " 99% 254/256 [10:12<00:09,  4.65s/it]\u001b[A\n",
            "100% 255/256 [10:16<00:04,  4.67s/it]\u001b[A\n",
            "100% 256/256 [10:21<00:00,  2.43s/it]\n",
            "1it [10:21, 621.80s/it]done\n",
            "generated images saved\n",
            "creating encoded test csv file\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "3it [00:00, 28.95it/s]\u001b[A\n",
            "6it [00:00, 28.55it/s]\u001b[A\n",
            "9it [00:00, 27.42it/s]\u001b[A\n",
            "12it [00:00, 27.29it/s]\u001b[A\n",
            "15it [00:00, 27.41it/s]\u001b[A\n",
            "18it [00:00, 27.16it/s]\u001b[A\n",
            "21it [00:00, 27.02it/s]\u001b[A\n",
            "24it [00:00, 27.38it/s]\u001b[A\n",
            "27it [00:01, 26.75it/s]\u001b[A\n",
            "30it [00:01, 26.64it/s]\u001b[A\n",
            "33it [00:01, 25.69it/s]\u001b[A\n",
            "36it [00:01, 25.96it/s]\u001b[A\n",
            "39it [00:01, 26.67it/s]\n",
            "saved encoded\n",
            "encoded test csv saved\n",
            "creating encoded train csv file\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "3it [00:00, 26.93it/s]\u001b[A\n",
            "6it [00:00, 27.61it/s]\u001b[A\n",
            "9it [00:00, 27.72it/s]\u001b[A\n",
            "12it [00:00, 28.14it/s]\u001b[A\n",
            "15it [00:00, 28.27it/s]\u001b[A\n",
            "18it [00:00, 27.30it/s]\u001b[A\n",
            "21it [00:00, 27.73it/s]\u001b[A\n",
            "24it [00:00, 27.22it/s]\u001b[A\n",
            "27it [00:00, 26.91it/s]\u001b[A\n",
            "30it [00:01, 26.99it/s]\u001b[A\n",
            "33it [00:01, 27.12it/s]\u001b[A\n",
            "36it [00:01, 26.48it/s]\u001b[A\n",
            "39it [00:01, 26.43it/s]\u001b[A\n",
            "42it [00:01, 26.23it/s]\u001b[A\n",
            "45it [00:01, 25.96it/s]\u001b[A\n",
            "48it [00:01, 25.70it/s]\u001b[A\n",
            "51it [00:01, 25.73it/s]\u001b[A\n",
            "54it [00:02, 25.74it/s]\u001b[A\n",
            "57it [00:02, 25.00it/s]\u001b[A\n",
            "60it [00:02, 25.28it/s]\u001b[A\n",
            "63it [00:02, 25.61it/s]\u001b[A\n",
            "66it [00:02, 25.23it/s]\u001b[A\n",
            "69it [00:02, 25.19it/s]\u001b[A\n",
            "72it [00:02, 24.33it/s]\u001b[A\n",
            "75it [00:02, 24.93it/s]\u001b[A\n",
            "78it [00:02, 25.34it/s]\u001b[A\n",
            "81it [00:03, 25.26it/s]\u001b[A\n",
            "84it [00:03, 25.44it/s]\u001b[A\n",
            "87it [00:03, 25.44it/s]\u001b[A\n",
            "90it [00:03, 25.07it/s]\u001b[A\n",
            "93it [00:03, 24.76it/s]\u001b[A\n",
            "96it [00:03, 24.15it/s]\u001b[A\n",
            "99it [00:03, 24.15it/s]\u001b[A\n",
            "102it [00:03, 23.49it/s]\u001b[A\n",
            "105it [00:04, 23.87it/s]\u001b[A\n",
            "108it [00:04, 23.89it/s]\u001b[A\n",
            "111it [00:04, 24.10it/s]\u001b[A\n",
            "114it [00:04, 23.20it/s]\u001b[A\n",
            "117it [00:04, 23.60it/s]\u001b[A\n",
            "120it [00:04, 23.38it/s]\u001b[A\n",
            "123it [00:04, 23.59it/s]\u001b[A\n",
            "126it [00:04, 23.61it/s]\u001b[A\n",
            "129it [00:05, 23.43it/s]\u001b[A\n",
            "132it [00:05, 23.49it/s]\u001b[A\n",
            "135it [00:05, 22.60it/s]\u001b[A\n",
            "138it [00:05, 20.51it/s]\u001b[A\n",
            "141it [00:05, 19.63it/s]\u001b[A\n",
            "144it [00:05, 20.13it/s]\u001b[A\n",
            "147it [00:06, 20.50it/s]\u001b[A\n",
            "150it [00:06, 21.12it/s]\u001b[A\n",
            "153it [00:06, 21.44it/s]\u001b[A\n",
            "156it [00:06, 21.59it/s]\u001b[A\n",
            "159it [00:06, 21.85it/s]\u001b[A\n",
            "162it [00:06, 22.04it/s]\u001b[A\n",
            "165it [00:06, 21.37it/s]\u001b[A\n",
            "168it [00:06, 21.61it/s]\u001b[A\n",
            "171it [00:07, 21.78it/s]\u001b[A\n",
            "174it [00:07, 21.62it/s]\u001b[A\n",
            "177it [00:07, 21.77it/s]\u001b[A\n",
            "180it [00:07, 21.89it/s]\u001b[A\n",
            "183it [00:07, 21.74it/s]\u001b[A\n",
            "186it [00:07, 21.81it/s]\u001b[A\n",
            "189it [00:07, 21.60it/s]\u001b[A\n",
            "192it [00:08, 21.52it/s]\u001b[A\n",
            "195it [00:08, 21.66it/s]\u001b[A\n",
            "198it [00:08, 21.43it/s]\u001b[A\n",
            "201it [00:08, 20.90it/s]\u001b[A\n",
            "204it [00:08, 20.89it/s]\u001b[A\n",
            "207it [00:08, 20.93it/s]\u001b[A\n",
            "210it [00:08, 20.83it/s]\u001b[A\n",
            "213it [00:09, 20.75it/s]\u001b[A\n",
            "216it [00:09, 20.99it/s]\u001b[A\n",
            "219it [00:09, 19.89it/s]\u001b[A\n",
            "222it [00:09, 20.16it/s]\u001b[A\n",
            "225it [00:09, 19.98it/s]\u001b[A\n",
            "228it [00:09, 19.88it/s]\u001b[A\n",
            "231it [00:09, 19.78it/s]\u001b[A\n",
            "234it [00:10, 23.06it/s]\n",
            "saved encoded\n",
            "encoded train csv saved\n",
            "1it [10:46, 646.65s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RztjY9D-Ba5M"
      },
      "source": [
        "### Linear Accuracy\n",
        "\n",
        "knn (n=3) classification score : 0.11\n",
        "\n",
        "I believe results would be better with more training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOusPBiTkM6k",
        "outputId": "6d4e8e5f-b5d3-48ac-9a7c-fb44d175e20f"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sx/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sx/encoded/test.csv\")\n",
        "\n",
        "train_y, train_X = train_df.loc[:, \"0\"], train_df.loc[:, \"1\":\"100\"]\n",
        "test_y, test_X = test_df.loc[:, \"0\"], test_df.loc[:, \"1\":\"100\"]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(train_X, train_y)\n",
        "neigh.score(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11117788461538461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIqXg8v6BvPC"
      },
      "source": [
        "### FID\n",
        "\n",
        "score = 10.53\n",
        "\n",
        "occluding SX worsens model drastically!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaIIoEETkNhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2c5b4b-817c-490f-a998-c22145f494a7"
      },
      "source": [
        "!python -m pytorch_fid \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/org/\" \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sx/gen/\" --dims 192 --device \"cuda\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:00<00:00, 123MB/s] \n",
            "100% 6/6 [00:51<00:00,  8.60s/it]\n",
            "100% 6/6 [00:01<00:00,  3.77it/s]\n",
            "FID:  10.53694765061347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhU7pZhICbDc"
      },
      "source": [
        "## No SX and No SZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V54zdCFCfS7"
      },
      "source": [
        "in this mode S_x and S_z are both turned off but their combination S_xz is still remained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjRTkqpXCo80"
      },
      "source": [
        "### Training\n",
        "\n",
        "--loss_mode: \"no_sx_sz\"\n",
        "\n",
        "--train: 1\n",
        "\n",
        "epoch 9, disc_loss 0.0, gen_enc_loss 40.13097381591797"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICtERqm9CeAR",
        "outputId": "b223de85-ef31-40a3-cdb7-7262201ec780"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 1 --loss_mode \"no_sx_sz\" --resume 7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from checkpoint, resuming from epoch: 7\n",
            "creating model from checkpoint\n",
            "2021-05-20 15:23:02.755184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "0it [00:00, ?it/s]epoch 7, disc_loss 0.0, gen_enc_loss 41.08757019042969\n",
            "50it [00:46,  1.10it/s]epoch 7, disc_loss 0.0, gen_enc_loss 40.55833435058594\n",
            "100it [01:32,  1.09it/s]epoch 7, disc_loss 0.0, gen_enc_loss 41.22679901123047\n",
            "150it [02:18,  1.07it/s]epoch 7, disc_loss 0.0, gen_enc_loss 39.203975677490234\n",
            "200it [03:05,  1.08it/s]epoch 7, disc_loss 0.0, gen_enc_loss 40.48166275024414\n",
            "234it [03:36,  1.08it/s]\n",
            "0it [00:00, ?it/s]epoch 8, disc_loss 0.0, gen_enc_loss 40.6639289855957\n",
            "50it [00:47,  1.08it/s]epoch 8, disc_loss 0.0, gen_enc_loss 39.579322814941406\n",
            "100it [01:33,  1.08it/s]epoch 8, disc_loss 0.0, gen_enc_loss 41.251155853271484\n",
            "150it [02:19,  1.09it/s]epoch 8, disc_loss 0.0, gen_enc_loss 40.55229187011719\n",
            "200it [03:06,  1.08it/s]epoch 8, disc_loss 0.0, gen_enc_loss 40.67505645751953\n",
            "234it [03:38,  1.07it/s]\n",
            "0it [00:00, ?it/s]epoch 9, disc_loss 0.0, gen_enc_loss 40.13097381591797\n",
            "50it [00:47,  1.07it/s]epoch 9, disc_loss 0.0, gen_enc_loss 41.31450653076172\n",
            "74it [01:10,  1.08it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4cJFiRPPdP6"
      },
      "source": [
        "### Testing \n",
        "\n",
        "--train: 0\n",
        "\n",
        "Inception Score is ::::::  1.0014774"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU0Ig8WmHQsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf078e4-be30-4af5-a2bd-5f0204c083a2"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"no_sx_sz\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original images saved\n",
            "creating generated image directory (save one batch\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:08<00:00, 12.4MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/drive/MyDrive/BigBiGAN-PyTorch-main/src/pipeline/pipeline.py:235: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n",
            "___________________________________\n",
            "Inception Score is ::::::  1.0014774\n",
            "___________________________________\n",
            "100% 256/256 [09:18<00:00,  2.18s/it]\n",
            "done\n",
            "generated images saved\n",
            "creating encoded test csv file\n",
            "39it [00:01, 28.81it/s]\n",
            "saved encoded\n",
            "encoded test csv saved\n",
            "creating encoded train csv file\n",
            "234it [00:09, 23.89it/s]\n",
            "saved encoded\n",
            "encoded train csv saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5WxIZCCPmup"
      },
      "source": [
        "### Linear Accuracy\n",
        "\n",
        "0.18209134615384615\n",
        "\n",
        "better than all other modes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVTxUqs6Fy_c",
        "outputId": "3d4e0601-3d7b-4950-9ab8-ace733c8d308"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sx_sz/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sx_sz/encoded/test.csv\")\n",
        "\n",
        "train_y, train_X = train_df.loc[:, \"0\"], train_df.loc[:, \"1\":\"100\"]\n",
        "test_y, test_X = test_df.loc[:, \"0\"], test_df.loc[:, \"1\":\"100\"]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(train_X, train_y)\n",
        "neigh.score(test_X, test_y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18209134615384615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqiz60ZUPs4w"
      },
      "source": [
        "### FID\n",
        "\n",
        "FID:  126.5791716644983\n",
        "\n",
        "very big!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnGeWaxoK2jp",
        "outputId": "f2f23159-e3ed-40d8-ad73-134d1c31cfe9"
      },
      "source": [
        "!python -m pytorch_fid \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/org/\" \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/no_sx_sz/gen/\" --dims 192 --device \"cuda\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:01<00:00, 64.9MB/s]\n",
            "100% 6/6 [00:52<00:00,  8.75s/it]\n",
            "100% 6/6 [00:01<00:00,  3.96it/s]\n",
            "FID:  126.5791716644983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U-TnPHkAZYS"
      },
      "source": [
        "# InfoGAN: Continued\n",
        "\n",
        "this is the testing phase of infogan which we trained in the previous notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgNeL_ETAgb9"
      },
      "source": [
        "### Testing\n",
        "\n",
        "Inception Score is ::::::  1.0814807"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8Mhf84J58dg",
        "outputId": "c104657a-f181-424c-f474-86f876d2ed63"
      },
      "source": [
        "!python \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/train_gan.py\" --dataset \"MNIST\" --data_path \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/\" --train 0 --loss_mode \"info_gan\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating C gen directory for InfoGAN\n",
            "\r0it [00:00, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "1it [00:03,  3.81s/it]done\n",
            "1it [00:03,  3.84s/it]\n",
            "original images saved\n",
            "creating generated image directory (save one batch\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:01<00:00, 55.2MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/drive/MyDrive/BigBiGAN-PyTorch-main/src/pipeline/pipeline.py:236: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n",
            "___________________________________\n",
            "Inception Score is ::::::  1.0814807\n",
            "___________________________________\n",
            "100% 256/256 [11:04<00:00,  2.60s/it]\n",
            "done\n",
            "generated images saved\n",
            "creating encoded test csv file\n",
            "39it [00:01, 29.14it/s]\n",
            "saved encoded\n",
            "encoded test csv saved\n",
            "creating encoded train csv file\n",
            "234it [00:09, 24.01it/s]\n",
            "saved encoded\n",
            "encoded train csv saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79eryddiAkpL"
      },
      "source": [
        "### FID\n",
        "\n",
        "FID is "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVijYUrEAHVW",
        "outputId": "02bf86bd-da70-451b-fdef-3c4a3d99b6be"
      },
      "source": [
        "!python -m pytorch_fid \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/org/\" \"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/info_gan/gen/\" --dims 192 --device \"cuda\""
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:01<00:00, 82.6MB/s]\n",
            "100% 6/6 [00:54<00:00,  9.15s/it]\n",
            "100% 6/6 [00:01<00:00,  3.93it/s]\n",
            "FID:  7.761327930667729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxzQgkmDAmwe"
      },
      "source": [
        "### Linear Accuracy\n",
        "\n",
        "linear accuracy is "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDnSwbPYACcE",
        "outputId": "1d04237f-b8f7-4985-e260-eb9894db21d7"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/info_gan/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/info_gan/encoded/test.csv\")\n",
        "\n",
        "train_y, train_X = train_df.loc[:, \"0\"], train_df.loc[:, \"1\":\"100\"]\n",
        "test_y, test_X = test_df.loc[:, \"0\"], test_df.loc[:, \"1\":\"100\"]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(train_X, train_y)\n",
        "neigh.score(test_X, test_y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14733573717948717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhSusBmGAqLz"
      },
      "source": [
        "### Hungarian Matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "N8L-VjnQ3Ume",
        "outputId": "c765bec9-fa24-4b4c-f49a-d9e67127047a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/info_gan/encoded/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/BigBiGAN-PyTorch-main/data/MNIST/bigbigan/info_gan/encoded/test.csv\")\n",
        "\n",
        "# Jobs are class labels\n",
        "jobs = train_df.loc[:, \"0\"].astype(int)\n",
        "# workers are predicted C in infoGAN\n",
        "workers = train_df.loc[:, \"1\":\"10\"]\n",
        "\n",
        "# predicted C is in one-hot mode -> cast to integer\n",
        "workers = workers.apply(lambda x: x.argmax(), axis=1)\n",
        "\n",
        "df = pd.DataFrame(list(zip(jobs, workers)), columns = ['label', 'predict'])\n",
        "df"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59899</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59900</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59901</th>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59902</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59903</th>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59904 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  predict\n",
              "0          9        9\n",
              "1          9        1\n",
              "2          2        2\n",
              "3          1        1\n",
              "4          3        0\n",
              "...      ...      ...\n",
              "59899      0        9\n",
              "59900      0        5\n",
              "59901      8        9\n",
              "59902      1        8\n",
              "59903      6        9\n",
              "\n",
              "[59904 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7NqbRAW3fnu",
        "outputId": "f20f6fd2-64e8-46a2-8664-1b529237c311"
      },
      "source": [
        "# Find how many times each label-predict pair happens \n",
        "# We use this to define cost function\n",
        "# The more 2 values appear together, the less the cost\n",
        "res = pd.Series(list(zip(df.label, df.predict))).value_counts()\n",
        "res"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)    1544\n",
              "(0, 5)    1521\n",
              "(2, 5)    1504\n",
              "(8, 5)    1485\n",
              "(3, 5)    1396\n",
              "          ... \n",
              "(8, 7)     205\n",
              "(3, 7)     199\n",
              "(2, 7)     187\n",
              "(0, 7)     183\n",
              "(5, 7)     178\n",
              "Length: 100, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIYx3SNHGE8o"
      },
      "source": [
        "this is the cost matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMnTh0la5F5e",
        "outputId": "b72ebfd5-4781-43b0-faaa-619fe3de933b"
      },
      "source": [
        "# Create worker job matrix\n",
        "worker_job_matrix = np.zeros((10, 10))\n",
        "\n",
        "for ind, cost in res.iteritems():\n",
        "  # - cost \n",
        "  worker_job_matrix[ind[0], ind[1]] = - cost\n",
        "\n",
        "print(worker_job_matrix)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -323.  -257.  -507. -1003.  -819. -1521.  -276.  -183.  -266.  -762.]\n",
            " [ -462.  -333.  -375. -1544.  -471. -1294.  -369.  -475.  -619.  -796.]\n",
            " [ -331.  -330.  -490. -1055.  -824. -1504.  -300.  -187.  -230.  -697.]\n",
            " [ -370.  -368.  -508.  -930.  -854. -1396.  -277.  -199.  -287.  -932.]\n",
            " [ -353.  -310.  -463.  -953.  -815. -1191.  -336.  -255.  -426.  -728.]\n",
            " [ -402.  -375.  -434.  -748.  -750. -1135.  -287.  -178.  -289.  -809.]\n",
            " [ -303.  -384.  -447. -1018.  -823. -1345.  -329.  -221.  -326.  -714.]\n",
            " [ -436.  -351.  -502. -1090.  -699. -1299.  -391.  -351.  -449.  -686.]\n",
            " [ -319.  -327.  -453. -1012.  -825. -1485.  -248.  -205.  -256.  -714.]\n",
            " [ -366.  -367.  -467.  -980.  -799. -1261.  -328.  -283.  -341.  -743.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRwih56xF4ux"
      },
      "source": [
        "this is the hungarian matching: \n",
        "\n",
        "each element in the left array is assigned to the corresponding element in right array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1SLg9WgEl56",
        "outputId": "47c99d07-ae37-4b1b-9676-f1e3309fbbb1"
      },
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "classes, mapping = linear_sum_assignment(worker_job_matrix)\n",
        "classes, mapping"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([5, 3, 2, 9, 8, 0, 1, 7, 4, 6]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7JE48YDGUp4"
      },
      "source": [
        "finding accuracy in test dataset:::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWfDj103FYDs",
        "outputId": "a5f6923e-94fc-4389-eda8-0e471f82d2a4"
      },
      "source": [
        "classes = test_df.loc[:, \"0\"].astype(int)\n",
        "predictions = test_df.loc[:, \"1\":\"10\"]\n",
        "predictions = predictions.apply(lambda x: x.argmax(), axis=1)\n",
        "# Mapping to true classes\n",
        "predictions = predictions.apply(lambda x: np.where(mapping == x)[0][0])\n",
        "\n",
        "# Finding Accuracy:\n",
        "df = pd.DataFrame(list(zip(classes, predictions)), columns=['classes', 'prediction'])\n",
        "print(\"Score on test dataset is \")\n",
        "len(df[df.prediction == df.classes]) / len(df)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score on test dataset is \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1162860576923077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVxGJEr6HlpJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}